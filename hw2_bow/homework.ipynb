{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccc8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "    train.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vectorizer_model: object,\n",
    "            vectorizer_args : dict,\n",
    "            classifier_model: object,\n",
    "            classifier_args : dict\n",
    "        ):\n",
    "        \n",
    "        self.vectorizer = vectorizer_model(**vectorizer_args)\n",
    "        X = self.vectorizer.fit_transform(self.train.comment)\n",
    "        y = self.train.toxic.values\n",
    "\n",
    "        self.classifier = classifier_model(**classifier_args)\n",
    "        self.classifier.fit(X, y)\n",
    "\n",
    "    def get_test_preds(self):\n",
    "        X = self.vectorizer.transform(self.test.comment)\n",
    "        preds = self.classifier.predict(X)\n",
    "        return preds\n",
    "\n",
    "    def get_report(self):\n",
    "        return classification_report(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0\n",
    "        )\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return f1_score(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_default = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {},\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be10bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      1.00      0.84       959\n",
      "         1.0       0.97      0.26      0.41       483\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.85      0.63      0.62      1442\n",
      "weighted avg       0.81      0.75      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_default.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d0945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Если просто сунуть по ссылке, прилетает TypeError: '<' not supported between instances of 'Substring' and 'Substring'\n",
    "\n",
    "def odel_tokenize(text):\n",
    "    return [_.text for _ in razdel.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c556e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_razdel = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {\n",
    "        \"tokenizer\": odel_tokenize,\n",
    "        \"analyzer\" : \"word\"\n",
    "    },\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06dc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       959\n",
      "         1.0       0.98      0.20      0.33       483\n",
      "\n",
      "    accuracy                           0.73      1442\n",
      "   macro avg       0.85      0.60      0.58      1442\n",
      "weighted avg       0.80      0.73      0.66      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_razdel.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f919aa1",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В документации Razdel написано, что\n",
    "\n",
    "<q>\n",
    "Правила в Razdel оптимизированы для аккуратно написанных текстов с правильной пунктуацией. Решение хорошо работает с новостными статьями, художественными текстами. На постах из социальных сетей, расшифровках телефонных разговоров качество ниже.\n",
    "</q>\n",
    "\n",
    "Поэтому неудивительно, что на данном датасете Razdel работает чуть хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = (\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": MultinomialNB,\n",
    "        \"classifier_args\" : {},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        ##  Здесь и далее наилучшие результаты давала векторизация с параметрами analyzer + ngram_range + max_df\n",
    "        ##  Т.е. с 3-мя вручную заданными параметрами, поэтому 2 отставшихся по заданию забил дефолтными.\n",
    "        ##  Иные вмешательства делали результат хуже.\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    ##  Фактически задание не выполнено т.к. в обоих случаях результаты получаются лучше с мешком слов.\n",
    "    ##  Однако вот такая конфигурация проходит только с варнингом, поэтому можно считать, что TF-IDF лучше т.к. стабильнее (?)\n",
    "    {   \n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": TfidfVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\tCountVectorizer\n",
      "F1:  0.8726114649681529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       959\n",
      "         1.0       0.90      0.85      0.87       483\n",
      "\n",
      "    accuracy                           0.92      1442\n",
      "   macro avg       0.91      0.90      0.91      1442\n",
      "weighted avg       0.92      0.92      0.92      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\tCountVectorizer\n",
      "F1:  0.837108953613808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92       959\n",
      "         1.0       0.87      0.80      0.84       483\n",
      "\n",
      "    accuracy                           0.90      1442\n",
      "   macro avg       0.89      0.87      0.88      1442\n",
      "weighted avg       0.89      0.90      0.89      1442\n",
      "\n",
      "LogisticRegression\tTfidfVectorizer\n",
      "F1:  0.8216340621403913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92       959\n",
      "         1.0       0.92      0.74      0.82       483\n",
      "\n",
      "    accuracy                           0.89      1442\n",
      "   macro avg       0.90      0.85      0.87      1442\n",
      "weighted avg       0.90      0.89      0.89      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_experiments = []\n",
    "\n",
    "for d in experiment_params:\n",
    "    experiment = Experiment(**d)\n",
    "    print(f'{d[\"classifier_model\"].__name__}\\t{d[\"vectorizer_model\"].__name__}')\n",
    "    print(\"F1: \", experiment.get_f1())\n",
    "    print(experiment.get_report())\n",
    "    finished_experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3ab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Для читаемости\n",
    "nb_bow_preds       = finished_experiments[0].get_test_preds()\n",
    "logreg_bow_preds   = finished_experiments[1].get_test_preds()\n",
    "logreg_tfidf_preds = finished_experiments[2].get_test_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f4dd5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "42f30332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_10_most_toxic(texts:list[str], experiment:Experiment):\n",
    "    vectors = experiment.vectorizer.transform(texts)\n",
    "    probas = experiment.classifier.predict_proba(vectors)\n",
    "    counter = Counter({\n",
    "        text: proba[1]\n",
    "        for text, proba\n",
    "        in zip(\n",
    "            texts, probas\n",
    "        )\n",
    "    })\n",
    "\n",
    "    return counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f70e4fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Верблюдов-то за что? Дебилы, бл...\\n', np.float64(1.0)),\n",
       " ('Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\\n',\n",
       "  np.float64(1.0)),\n",
       " ('тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Для каких стан является эталоном современная система здравоохранения РФ? Для Зимбабве? Ты тупой? хохлы\\n',\n",
       "  np.float64(1.0)),\n",
       " ('В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РАЗВОРУЮТ КАК ВСЕГДА! УЖЕ ТРЕЩИНАМИ ПОШ Л! ТУПЫЕ КИТАЗЫ НЕ МОГУТ НИЧЕГО НОРМАЛЬНО СДЕЛАТЬ!\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Ебать тебя разносит, шизик.\\n', np.float64(1.0)),\n",
       " ('Обосрался, сиди обтекай\\n', np.float64(1.0)),\n",
       " ('Зачем ты пишешь хуйню, дегенерат? Поцелуй в губы ! поцелую в засос.\\n',\n",
       "  np.float64(1.0))]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_10_most_toxic(data.comment, finished_experiments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dbb778f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ну давай разберём всё тобой написанное. Бляядь, вы действительно думаете вы лучше пидорашек? Ну в целом, всё что живёт в рашке - затронуто говномидасом, но никто тут это не признает. сейчас воспитывают массу хороших кодеров В соседнем треде обоссали уже. Иди обтекай. Вы унижаете русских детей в школе Я учился в рашке и у нас был класс, который состоял онли из русачков. Думаешь, что то изменилось? Чурки тебе говна в жопу залили и заставили русачков в классе кошмарить омежных русачков? Я не люблю выражаться фразами нациков, но вы воистину столетия просто сидели в горах и ебали баранов, вас даже народ-пидор смог захватить. Плоховато ты знаешь историю. Когда русня пришла на Кавказ, тут всё уже было поделено османами и персами. А потом РИ наебала персов и постоянно нападала на османов высасывая причины из пальца, в принципе, русачки, что от них ещё было ожидать. В прошлом вы (чеченцы, даги и прочие сорта) были просто дикарями...А если говорить о среднеазиатах, которые бугуртят с оккупации, то вы были обычными нищими кочевниками Очередной акт незнания истории. Например у кавказцев по факту у народов отвественных за этногенез дагов и азеров уже был Дербент, а русачков даже в планах не было. Почитай историю Кавказа и Средней Азии, там были и локальные империи и нагибы округи и прочее и прочее. Называют русских пидорашками, славщитом. Говоришь это так, будто бы в этом что то плохое. У меня знакомые po рашеры irl, которые являются русскими и которые ссут на русню с ещё большей колокольни чем я Сейчас вас все боятся потому, что если пидорашка сделает в вас пару дырок, защищая себя, то его посадят на бутылку, а если вы убьёте пидорашку, то вам нихуя не будет. Может потому что в рашке мочить с волыны ножа человека, который идёт на тебя с кулаками - превышение пределов самообороны? Кто виноват в том, что русня настолько вырожденческая, что один чеченский доходяга ставит на колени группу русачков? Ты думаешь, будь руснявая гопота менее вырожденческая, то так же людей не кошмарила? Кто виноват, что вы морозитесь или даёте по съебатору, когда видите, как вашего славянского друга избивают унижают? Да чего уж там, тот митинг вспомните, где жирик, какого то парня на колени поставил и все вокруг стоят и снимают, словно стадо руснявых баранов. Зуб даю, в той толпе стояли его друзья и знакомые. Лично для меня это пиздец, особенно проигрываю, когда там не какой нибудь братуха-борцуха, а смарчёк чеченский. Никогда бы не бросил и не бросал друга в таком пиздеце и не важно, какой нации был друг, а какой нападавший. Вся ваша проблема не том, что вы слабками, не в том, что большинство русачков еблом похож на свинью, не в том, что за тысячу лет существования не смогли построить нормальную цивилизацию и другим не давали. Проблема в обыкновенной ошибке выжившего, вы видите кавказское быдло гопника, потому что оно в среднем сильнее, напористее, агрессивнее и образ кавказца, как лица которое представляет опасность выжигается у вас в мозгах, при этом не хотите замечать, что у вас, целые города набитые руснявыми АУЕшниками, потому что один среднестатистический руснявый гопник ауешник быдлойд сосёт у одного среднестатистического чуркобесского гопника быдлойда. В конечном итоге русачков в станице кущевской ебал кто? Другие русачки. В школу приезжали и выберали лолей на поёбку кто? Другие русачки. Сжигал русачков кто? Другие русачки. Всё вскрылось совершенно случайно. Сколько таких станиц, деревень и городов по всей рашке? аз-кун\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Твоих граждан ? Твои товары ? у ВАС растёт продолжительность жизни? Те гауляйтеры - это ты и твои хозяева-кормильцы, предающие и насилующие российский народ ЕЖЕДНЕВНО И ЕЖЕЧАСНО. Вы торгуете недрами, вы пытаетесь пристроить награбленное подальше от ограбляемогонарода, вы наполнили страну полицаями , защищающими исключительно ваши интересы от российского народа. Вы гоните в НАТО нефть, газ, лес и прочие ресурсы, которые воруете у россиян, вы обложили данью всех от мелких и крупных торговцев, до самозанятых , выживающих в беспределе грабежа и воровства, творимого вами в стране. Вы оплачиваете свои права кровью и потом народа. Свои права по уничтожению этого самого народа. Деньги ВЫ превратили в мерило прав. Право на здравоохранение, образование, защиту и все базовые права ВЫ требуете оплачивать, не считая людьми и гражданами никого, кроме тех,кто это всё оплатит звонкой монетой. И войска НАТО приведёте в страну тоже ВЫ. Своей неудержимой жаждой денег и власти. Так же, как это сделал ваш свято-кровавый николашка , приведя в Россию своих партнёров . Они - ВАШИ партнёры - не мои. Так вот, знайте. Когда ваши партнёры по грабительскому бизнесу придут лишать ВАС вашей доли, и вы, и они будут по другую сторону фронта от меня и российского народа - точно так же, как вы и они ВМЕСТЕ по другую сторону фронта экономического все последние 30 лет. Я за ваши головы не дам и гнилой картошины. Так что, бойтесь не их. Бойтесь нас. Они для меня - просто враги, а ВЫ - ПРЕДАТЕЛИ СОБСТВЕННОГО НАРОДА, говно безродное, НЕЛЮДИ. И только очистив страну от таких как вы, возможно её защитить от них. Запиши на обороте своей методички, и передай по команде.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Создал тут тхреад в b 192441781 Как оказалось, ЛГБТ пропаганда в б кажется унылой и слишком обильной не только мне. Как насчёт пидорнуть все гее би треды из b в ga? Хуле они тут у себя филиал открыли? Заебали притеснять натуралов. Давайте я поясню. Пидоротреды унылы и неприятны, и их крайне много. Это заебало. Если куклоебов и пониебоы пидорнули, почему пидоров нельзя пидорнуть? Пониебы всех заебали - их пидорнули Куклоебы всех заебали - их пидорнули Пидоротреды заебали меня, я интересуюсь, сколько ещё анонов заебались их видить нонстоп 24 7 на главной. Если нас будет много - можно и пидорнуть, я считаю. Для них есть целый раздел, или 2-3 даже. Но все равно постоянно это лезет на главную в b. ДОКОЛЕ?\\n',\n",
       "  np.float64(1.0)),\n",
       " ('С каких пор порноскримеры нарушают что-то В том и проблемы, что не нарушают ничего, и нашелся умник, начавший этим злоупотреблять и использовать тред для своего увеселения. Свобода ебать, что хочет то и вставляет. Иди поезд-тред создай, зацени свободу. Я уже не говорю об аниме треде, где трут постоянно и хуй пойми что и за что. Там никакой проблемы с удалением постов нет, а как из вебм треда удалить десяток постов, и въебать банхаммером по голове одному (одному, блядь!) дебилу, так это нет, отказывают клавиатуры, мышки, пропадает интернет и отсыхают руки. Ну не могут эти ебаные мочераторы почистить говно там, где их просят. Сделай вебмки тише и будет тебе Щасте. Серьезно? Я должен дрочить звук каждый раз, потому что какой-то дебил решил перед мамкой похвастаться, как он траллит двощи заброской скримеров? Ты гениален, ответ 10 10 просто. Так может и вайпы не трогать, ну не понравился тред кому-то, или просто захотелось повеселиться. Пусть остальные скрывают посты, куклу настраивают.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('В очередной раз убеждаюсь, что двачеры редкостные говноеды и хуесосы. Ладно там гоблин скурвился, ватанскую дичь уже давно несёт, но блять евген один из немногих блоггеров за которым нет явных грешков и провалов. Но блять сосачерам неприятна что он за совок топит, вот в чём причина , бугурта здесь многих. ПРОКЛЯТЫЙ САВВОК АРРЯ ГРЯЗНОШТАННИКИ ПИДАРАСЫ АРРЯ. Какой же дегенерат стандартный двачер, ты даже не человек блять, ебаный биомусор, неспособный понять обзорчик с ютуба. Способен только бомбить с абсолютно непонятных вещей, который видишь только ты, будь то злые коммуняки или пидарахи. Весь тред скатили не в обсуждение его лучших работ и скандалов, в том что евген блять КОММУНЯКА уххх печёт. Действительно, придерживался бы современных взглядов креативной молодёжи и был бы популярен как светов или сисян. но стоит отдать должое, у сисяна тоже ролики годные Видимо евген действительно знает что делает, раз его деятельность так подрывает дегенератов с нулевой. Охуенно\\n',\n",
       "  np.float64(1.0)),\n",
       " ('самый сброд червей-пидоров Не, ну если это черви-пидоры, то перечисленные тобой далее люди - это черви-пидоры в гуголплексе стаса какай просто Автор абсолютно неинтересного технического блога на Ютабе, пускай честного в отличие от Виласкома, но от того ничуть не менее унылого, любитель шутечек про куканы и поопускать маргиналов на тему не присаживал на них тёлку . соболева Говорящая голова народных масс, своего мнения не имеет, никогда в жизни не сделает ролик по какому-либо малооглашённому поводу, по хайповому не выскажет какую-либо точку зрения кроме той, которая будет угодно большинству. В жизни, по описанию очевидцев, быдловат. Продавал жопу Собянину, чем, ЧСХ, не может похвастаться никто из ОП-треда, кроме Хованского. амирана из дневника хача Никогда не понимал, кому он вообще нахуй нужен. Кому на полном серьёзе может доставлять наблюдать за жизнью мажора-рабовладельца, не сообщающего вам ничего полезного, или хотя бы как жить так же? Летсплеи на сто порядков более высокоинтеллектуальный и нужный контент, блеадь. Тоже продавал жопу Собянину. петушария Педофил-кремлебот, просто но комментс. гоблина Охуенный переводчик, но как человек говно. Указанные в ОП-треде личности определённо могут в интеллектуальные дискуссии, определённо не являются сцанными быдланами, и если и продают жопу, то только по праздникам. Несмотря на то что это неебаться борцуны с активной политической позицией, их борцунство почему-то только с совком, сралиным и члениным (которых нет) У Айтипедика немалая часть контента посвящена борьбе именно с текущей властью. и, на которых всем похуй кроме пары десятков тыщ сектантов Лол, ты рили не понимаешь, в чём тут соль? Тебе напомнить, что единственный человек, у которого рейтинг выше, чем у Пыни - это Сталин? 50 населения России в рот ебали Пыню и едро, но тащемта, хотели бы вернуться в Совок, потому их борцунство (благеров) преимущественно и с Совком.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Так ты не по теме гомофорса давай, а в общем. Нахуя ты машешь банхамером? Это не лично твоя доска - не нравится, как общаются некоторые аноны - пили свой сайт и там наводи собственные порядки. Сейчас все выглядит так, что ты встав с утра не с той ноги, начинаешь раздавать баны, увидев там некий намек на срач и пытаясь искусственно зарегулировать доску под какое-то свое виденье того, как доска должна выглядить. Системность следования правилам раздела, отсутствие избирательного отношения или фаворитизма по отношению к тому или иному форсу, - залог стабильного постинга на честной доске. Что ты несешь, шизофреник задроченный? Честная доска? Ты таблеток принял? Кто тебе вообще дал ограничивать право на форс других людей, к тому же относительно фентези сука. Это игра, здесь все выдуманное, але. И вообще, что ты имеешь против гомиков, говна кусок? Ты уже не стесняешься и решил открыто ссать всем обитателям tes в лицо? надоели и стали больно уж натужными, или форсед по-другому. Лично тебе? Повторюсь, создавай свой сайт. Поэтому аноны, упорствующие в гомофорсе, могут и будут забанены на средние сроки - неделю или две. Вообще охуел, чушок. Залетит такое быдло с вконтактов и пикабу, возьмет модераторку и давай из своих туповатых взглядов раздавать баны на право и на лево. Особо упорствующие могут попасть под пермач А я считаю, что тебя должны снять с этой доски. Абу, обрати внимание. Это ебанейший аутист. Таким вообще никакой власти нельзя доверять, это неполноценные люди - даже на доске про компьютерную игру. Совсем поехал, дружок.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Как известно, у Укр ины (т.е. окр ины), слепленной по пьяни на коленке во 2-м десятилетии XX в., нет истории до XX столетия. Все земли, которые сейчас занимает Укр ина, это русские, румынские, польские и венгерские земли. Напоминаем, что укр инство это сугубо левацкая, антиконсервативная местечково-хуторская идеология, направленная, как и прочие левацкие идеи, на разделение больших наций и поддержание диктата интернацистов. Сторонники бандеровцев (леваков, выступавших за бесклассовое общество и борьбу с капитализмом) и карлика-душителя котов Степана Бандеры, который, как известно, боролся с расизмом, поддерживал Идель-Урал и называл побратимами исламских борцов за свободу из Азербайджана, не пользуются симпатиями у правых европейцев. И это правильно. Попытки заявить о некой отдельной нации неких украинцев это манипуляции, созданные с целью оторвать от русских часть их этнических земель и ослабить в будущем Россию. Только так, чудовищной ложью и тотальной пропагандой, фейковая нация укр инцев , слепленная советскими кукловодами из русских Юга и Киевщины, галичан, поляков, советских румын, славянизированных гуцулов, закарпатских венгров, евреев, татар и многонациональных советских новиопов (а ля Бабченко), может обрести жизнь на русских этнических землях. Разумеется, нет никакого народа укр инцев , как бы одно соседнее failed state ни пыталось их вывести из русских путём обмана, коверканья истории и откровенной фальсификации. Нынешний эксперимент по созданию некой украинской нации можно сравнить разве что с советским экспериментом по созданию нации советской на основании таких же мифов, фейков и откровенного бреда. И маниакальное желание снести все памятники выродку Ленину (Бланку) вас не должно обнадёживать. На смену ему устанавливают памятники такого же левацкого дегенерата-кошкодава Бандеры, чьи руки по локоть в славянской (прежде всего, польской) крови. Заместо совковой лжи про Великую революцию Октября пришла точно такая же наглая ложь про Великую революц ю Г дност абстрагируйтесь от фигуры блогера и посмотрите видео Чем в итоге завершился советский эксперимент, мы все знаем. Ждём закономерного итога эксперимента эльфийского (простите, укр инского ). Разумеется, зомбированные люди будут цепляться до последнего за свои мифы про отельный народ и чужих московитов , но всё это наваждение рано или поздно сгинет, как сгинул Совок со своей мощной идеологией, мифами и фейками.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Стас, никому, кроме тебя и армии твоих подсосов(которые представляют собой типичный дегенеративный биомусор, ведущийся на любые скандалы-интриги), твои ролики нахуй не нужны. Серьёзно, ты сделал новости с целью показать, что такое говно может делать любой, а аудитория осталась на том же уровне, ведь людям извне ты не интересен. Да ещё и просит не подписываться, чтобы такую-то годноту ложкой хлебать подольше. Ты обосрался, стал посмешищем для абсолютно всех ютуберов, которые не являются полными ебланами. Тот же Хованский не ссыт тебе на ебало только потому, что ты вертишься с ним в одной компании, иногда даже лично пересекаетесь. Приятно было слышать, как он говорил, что отстреливался бы от таких, как ты, из огнестрела, стараясь забрать с собой побольше коммунистов, когда они придут его оаскулачиапть? Он открыто хуесосил людей и за меньшие грехи. Сложи 2 и 2, как он к тебе относится на самом деле. После чего ты сделал ещё более смешной ролик, где истеришь как побитая шлюха во время ПМС. Я ПОДЕБИЛ, А ЕСЛИ ВЫ НЕ ПОНЯЛИ ЭТОГО, ТО ВЫ ТУПЫЕ . Ты мог хотя бы сам его посмотреть перед заливом? Мне даже рофлить над тобой расхотелось, из смешного дегенерата, ты стал жалким дурачком. Это как смеятся над роликами, где контуженные ветераны пытаются ходить под клубную музыку. Над неполноценными смеятся плохо, даже стыдно стало. Я не утрирую. Просто посмотри на себя, Стас. Ну правда. Банишь людей в группе за лвйки и одно упоминание стрима. Ты делаешь всё, в чём самый отбитый и дегенеративный либераст обвиняет совок и сверкаешь разорванным очком. Никто тебя несправедливо не обсирал. Что на стриме по поводу дат, ну ты же сам проебался. На подкасте сообщил, что не будешь стримить. Если ты не был уверен, то зачем это говорить? А если был, почему не сообщил Маргиналу сразу же? Твоё слово в целом не стоит нихуя. Обещаешь не банить-куча удалённых комментов. Обещаешь стрим-не идёшь. Обещаешь что-то ещё, всегда проёбываешься, всё чаще на нарушение обещания тебе нужно в районе секунды-дня. Стоит ли удивлятся, что тебе за это прилетело? Когда то должно было. Ты сам срёшь себе в штаны, не злись, когда на это указывают пальцем.',\n",
       "  np.float64(1.0)),\n",
       " ('В Киеве на вокзале Мен було рок в 19, коли мене перший раз мав в зад хлопець рок в п д 30. Я тод перш рази став заходити на вокзал Ки в-Пасажирський в туалети - де були каб ни з д рками написи на ст нах. Так як досв ду ще не було н якого, то як знайомиться не уявляв. Сам перший природно не п дходив. А видивлявся на написи. дрочив св й член стоячи в каб нц . Хлопець був у сус дн й каб нц , в н побачив це, хитнув мен головою, запрошуючи п ти з ним. А так як н кого б льше в той момент не було, а був уже веч р, над на щось нше не було -все ж п шов за ним. У мене вже тод з явилася молофья - я вже спускав. Так як трохи ран ше ще не було, при дрочц робив це до при много стану - коли просто ставало дуже добре - але з хуя н чого не вид лялося. А до цього мен вже к лька раз в смоктали член хлопц мужики, я спускав м в рот, знав як це при мно. Ми прийшли б ля вокзалу кудись в кущ . В н розстебнув мен мотню, д став м й член став дрочити. А в той час нав ть це - коли хтось чужий рукою просто всього лише дрочив мен - було все одно дуже при мно. забирало. Бо коли тоб дрочать чужою рукою в дитинств - це вже щось: в д цього балд ш дуже. В н, ймов рно, здогадуючись, що перед ним зовс м новачок не намагався нав ть мен св й дати в руку: Так в н мене зав в , а пот м попросив повернутися: Я запитав нав що, справд не розум ючи нав що - а в н сказав треба так. я як теля повернувся п дкоряючись команд дорослого. В н приспустив мен штани, труси приставив до дерева у якого ми стояли, трохи нагнувши мене. А сам встав ззаду. По звуках я зрозум в, що в н розст ба соб свою мотню д ста св й член. В н притулився до мо поп сво м хуем, в д чого я здригнувся, але в н взяв мене за м й член знову став дрочити. А ншою рукою водити по стегнах з внутр шньо сторони. П д ймаючись в д кол н до поп - це посилювало кайф в д дрочк , я мл в, в н це теж в дчував, вже спок йно став тертися сво м хуем мен по поп . Пот м в н перестав дрочити мен , я почув як в н послинив св й член мою д рочку приставив мен св й член, в дсунув мене в д дерева трохи, пригнув мене почав засовували член в мене. Я стояв нагнувшись, упершись руками в дерево, н живий, н мертвий - перший раз в житт хлопець в мене засовував св й хуй! Я боявся - як все буде, що буде з мною, як це. Мен пощастило, звичайно, для першого разу, що у нього був маленький тонкий хуй. Тому н яких проблем у нього з всуванням його хуя в мою св жу попку не було. Оск льки мен не було боляче або непри мно я стояв не с паючись. Чекаючи як що буде дал :. В н засунув св й член весь в мене. т льки коли в н встромив його до к нця - було в дчуття що в н у щось уперся. Але не боляче зовс м. треба сказати чесно, що було при мно в дчувати, коли яйця його доторкнулися до мо попки, до д рочки, коли весь член був уже всередин не .. Це при мне в дчуття, коли умоглядно уявля ш що в тебе чийсь член засунуть: Це було мабуть нав ть при мн ше н ж все нше - в дчувати його яйця б ля очка. Коли весь член вже там. коли в н пот м став й бати мене, я намагався щоб част ше яйця його впиралися в попу мен , нав ть нод насаджувався сам глибше на його член, до упору. Але показувати що мен щось при мно тод здавалося ще не зручним - б льший час я просто стояв обхопивши дерево руками, а в н вставляв член в мене. Хоча особливого кайфу я ще тод не в дчував - було в дчуття - що просто в мене встромляв хлопець св й член ходив там. Так в н мав мене, продовжуючи одночасно весь цей час одн ю рукою дрочить мен - п дтримуючи в мен бажання: - ось в д цього мен було при мно. Природно. Це був його розрахунок. Я досить швидко в д дрочк чужою рукою спустив, в дразу з скочив з його члена. Але в дчув що у мене щось липкою ззаду на стегнах: Що щось тече по стегнах з очка. ось це мене засмутило сильно. вбило - я здогадався зрозум в що в н спустив в мене. Запитав, - Ти що ск нчив у мене? в н сказав - так. запитав мене - а ти що перший раз це робив? я мало не плачучи в д образи сказав - що так, перший раз: поставив йому дурне питання - нав що ти в мене спустив? Я не припускав цього, думав що в н просто посует ться в мене св й хуй все, а тут мен стало не по соб : було огидно, - особливо п сля того як сам пустив, - що на мен чужа гидота , як тод сприймав чужу малофю . Та тим б льше на сво му т л . Але справа була зроблена: хлопця 19 рок в видрали в дупу! спустили сперму йому в очко! В струнку, пружну, н жну попочку з н жною д рочкою, засунувши в не перший раз член! У перший момент було огидно в д того що щось липке, спочатку тепле, ст кало по стегнах, а пот м застигло так: (а так як не готувався до цього, то витерти було н чим:) Тод було прикро, не за те що ви бав, а що не попередивши, спустив в мене. Так як тод сперма сприймалася як щось мерзенне, тим б льше на соб . Пот м згадував про це вже з та мним насолодою, нав ть бажанням, щоб це повторилося: я поб г швидко з цього м сця, скор ше в д нього, а липка р дина на стегнах весь час нагадувала, що мене т льки що ви бли в жопу. Слава Укра н !',\n",
       "  np.float64(1.0))]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_10_most_toxic(data.comment, finished_experiments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4176d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\\n',\n",
       "  np.float64(1.0)),\n",
       " ('УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РАЗВОРУЮТ КАК ВСЕГДА! УЖЕ ТРЕЩИНАМИ ПОШ Л! ТУПЫЕ КИТАЗЫ НЕ МОГУТ НИЧЕГО НОРМАЛЬНО СДЕЛАТЬ!\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Ебать тебя разносит, шизик.\\n', np.float64(1.0)),\n",
       " ('Уроды!! у нас в семье 3 поколения там родились\\n', np.float64(1.0)),\n",
       " ('Можем на тебя ещё и модера за безмозглых позвать.\\n', np.float64(1.0)),\n",
       " ('Всем, кстати, наплевать. Главное - уровень жизни. Вдвойне наплевать на кукареканье тупорылого хохла с форума-помойки.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('В обеих странах есть партия войны . И в обеих странах эта война сейчас разжигается и поддерживается Смотрите, парни. И вот после этого руснявого пиздежа пидараны требуют к ним хорошего отношения? Мань, может это Украина хуярит по в на роисе градами ? Украина засылает в на роисю террористов бандитов ихтамнетов? Харк тебе в ебло, спидозная тварь.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Ох вау, а какой стороной ножа резать, не подскажешь? Дебил хвастается рязанским еблом, ещё и гуглит незнакомые словечки. Ну вся суть никому не нужного селюка с никому не нужным тредом.\\n',\n",
       "  np.float64(1.0)),\n",
       " ('Это совсем не смешно. Но уроды могут поржать. И им даже не объяснишь, что они уроды. Они приспособились с этим жить. Пока они потребляют, они удобны тому, кто продает им хавку и цацки, так что, скорее, верно ваше утверждение мир ебанутый , если совсем узко смотреть.\\n',\n",
       "  np.float64(1.0))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_10_most_toxic(data.comment, finished_experiments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7abe0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_normal_results      = []\n",
    "same_toxic_results       = []\n",
    "different_normal_results = []\n",
    "different_toxic_results  = []\n",
    "\n",
    "# for comment, is_toxic, nb_bow_pred, logreg_bow_pred, logreg_tfidf_pred \\\n",
    "for comment, results in zip(\n",
    "        Experiment.test.comment,\n",
    "        zip(\n",
    "            experiment.test.toxic,\n",
    "            nb_bow_preds,\n",
    "            logreg_bow_preds,\n",
    "            logreg_tfidf_preds\n",
    "        )\n",
    "    ):\n",
    "\n",
    "    elem_to_append = comment.strip() + \": \" + \" \".join(map(str, results))\n",
    "    if sum(results) in (0, 4):\n",
    "        if results[0] == 1:\n",
    "            same_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            same_normal_results.append(elem_to_append)\n",
    "    else:\n",
    "        if results[0] == 1:\n",
    "            different_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            different_normal_results.append(elem_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9775096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 885, 150, 74)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(same_toxic_results), len(same_normal_results), len(different_toxic_results), len(different_normal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836e6e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взгляните на пизду. Как психически здоровый человек захочет вставлять в эту мерзость? Женская издания это самый страшный орган человека.: 1.0 1.0 1.0 1.0\n",
      "ты такое же говно как и бомжи, т.к. у них гнилые органы, а у тебя мозг отупел и сгнил.: 1.0 1.0 1.0 1.0\n",
      "Отправить ты можешь только хуй в свою жопу, лахтодырка.: 1.0 1.0 1.0 1.0\n",
      "А из хохляндии сколько эмигрировало? А почему ты не говоришь, сколько приехало в Россию? только официальные - а есть ещё те, кто лесами границу переходил, что ли?: 1.0 1.0 1.0 1.0\n",
      "Ну это типично. Как он вёл? -нормально же: 1.0 1.0 1.0 1.0\n",
      "Надо просто Тарасов-пидорашек из по выгнать, тогда и генотьбы не будет. Нет свиньи - нет проблемы, как говорил создатель хохлов.: 1.0 1.0 1.0 1.0\n",
      "Пиздец, случайно зашел в ньюс. Тут у вас какая-то вакханалия творится. Одни отыгрывают за хохлов, другие за ватриотов. Пиздец, пойду отсюда нахуй, а то еще крыша поедет.: 1.0 1.0 1.0 1.0\n",
      "Мы казаки, ты а пидораха.: 1.0 1.0 1.0 1.0\n",
      "8.Комментаторы комментируют пост с комментариями комментаторов, комментирующих комментатора комментатора: 1.0 1.0 1.0 1.0\n",
      "Смешно тут наркоманам, наверно... я вот ничего не поняла: 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427fcf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я когда-то давно на рыбном заводе работал. Так там все приходили на работу через проходную. А после выходили через дыру в заборе с полными катомками рыбопродукции. Название у этой дыры было: выходная... Я к чему, если бутылка водки не пролезет через проходную, путь вам в выходную.: 0.0 0.0 0.0 0.0\n",
      "Глупость говорите, новая УК не отвечает за старую УК. Тем более замена радиатора это вообще не обязанность УК. Граница ответственность УК запирающее устройство, все после него - имущество собственника. Человек захотел себе радиатор поставить, спилив чугунную. За отдельную плату ее поставили, подписали акты, с этого момента радиатор собственника и он отвечает за его содержание и все последствия. Другое дело, что женщина может взыскать убытки с подрядчика, который установил ей кривой радиатор, но сначала ей придется эти убытки понести (то есть выплатить ущерб), да ещё и доказать, что радиатор реально кривой.: 0.0 0.0 0.0 0.0\n",
      "Ну тут, имхо, от магазина конкретного зависит все.: 0.0 0.0 0.0 0.0\n",
      "И ведь кто-то эту дорогу строил: 0.0 0.0 0.0 0.0\n",
      "а зачем там что то случайное? защита лицензию не подтвердила, игра отказалась работать: 0.0 0.0 0.0 0.0\n",
      "А я за всю жизнь ни разу не открывал такие холодильники: 0.0 0.0 0.0 0.0\n",
      "Улучшаются в архимагов палладия: 0.0 0.0 0.0 0.0\n",
      "Считается, что большая часть этой воды попросту высохла под воздействием солнечных ветров. Эээм, тупой вопрос. Если вода высохла, т.е. испарилась она не должна разве остаться на планете в виде облаков пара или выпасть где-нибудь в другом месте?: 0.0 0.0 0.0 0.0\n",
      "Я помню все пароли от всех карточек, которые меня были, хотя многих давно уже и нет! Я открывал бумагу с паролем, запоминал и выбрасывал через 5 минут.: 0.0 0.0 0.0 0.0\n",
      "потом напишу - куда судьба вырулит: 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "029df7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Блин, , до сих пор хрюкаю и ржу! Спасибо тебе! Ты мне создал хорошее настроение своим уточнением на длительное время! :-D: 1.0 0.0 0.0 0.0\n",
      "Форчан, Двач, Луркморье. Только вы там поосторожней, у них своя атмосфера.: 1.0 1.0 1.0 0.0\n",
      "А давайте не путать феминизм и идиотские высказывания тупых и страшных женщин, а? Феминизм-это желание иметь равные права в работе и в жизни, но быть женщиной, слабым прекрасным полом, как и происходит сейчас в нормальном обществе. Радфемки-это чудаковатые бабы, которые просто орут, что мужчины им не нужны и вообще все козлы. Во-вторых, каждая женщина и каждый мужчина имеют право выбирать спутника исходя из своих критериев. Другой вопрос, что под их критерии может рикто не попасть, или идеал их сам не захочет. Но осуждать их за это, смысл?: 1.0 1.0 1.0 0.0\n",
      "А у меня кандидатка завалилась на электрохромизме, не могут эти твари выдержать без разрушения больше 500 электрохимических циклов без разрушения тонких плёнок( Хотя чему я удивляюсь работы по электрохромизму идут с середины 70-х, а прикладных результатов до сих пор никто толком не выкатил.: 1.0 0.0 0.0 0.0\n",
      "Этот слабоумный покупает прокси же.: 1.0 1.0 0.0 0.0\n",
      "4, кастрированный, любит играть и носиться. И ещё гулять выходим, я покурить выхожу он со мной, побегает, по березам полазит и домой. И зимой на батарее любит валяться (батарея кожухом закрыта), дурачок бывает перележит перегреется сползает и на линолиуме остывает.: 1.0 0.0 0.0 0.0\n",
      "блин в коменты не дает фотки добавлять: 1.0 0.0 0.0 0.0\n",
      "Хромокей? Нее, не слышал...: 1.0 0.0 0.0 0.0\n",
      "Даже загадывать кого в расход пустят страшно... Пишу ,а сердечко нет нет да и попримолкнет...: 1.0 0.0 0.0 0.0\n",
      "Панкам мозги не можно с собой брать.: 1.0 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac6b7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А как насчет клеветы? Обвиняют, что виновен в дтп, когда человек не виновен.: 0.0 0.0 1.0 0.0\n",
      "Что за ролик? Тоже хочу такой звук: 0.0 1.0 0.0 0.0\n",
      "Хуй пойми за что тебя минусуют. Я ищу вот такую девушку - Да как ты посмел нам указывать, ко-ко-ко, это мои интересы . Что-то странная хуета: высказываешь свою позицию, оказывается ты угнетаешь девушек и вообще должен заткнуться и засунуть своё мнение в задницу.: 0.0 1.0 1.0 1.0\n",
      "Так же как бандосов. Есть авторитетный человек которому доверяют оба уголовника, тот их и судит.: 0.0 1.0 1.0 1.0\n",
      "Не все муслимы террористы, но все террористы - муслимы (до недавнего времени): 0.0 1.0 1.0 1.0\n",
      "Красивый мужик это пидр..: 0.0 1.0 1.0 1.0\n",
      "Что-то появившееся на небе пугает туристов Кто рассказал Черноброву про это, дух горы, мертвецы дятловцы?: 0.0 1.0 1.0 1.0\n",
      "меня тут на хуй послали и модератор даже не отреагировал, пришлось банить идиота. А ВЫ говорите, что работает .: 0.0 1.0 0.0 0.0\n",
      "А вот говорить что сниматься в порно хорошо, нормально, а распространять это порно среди родных и близких актрис - плохо. Серьезно, если в порно-шлюхах и их занятии нет ничего плохого, то что плохого случится если я отправлю ее творчество ее родителям? У них есть сексуальная жизньв отличие от меня, они это не осудят, а будут гордиться дочерью. Кек, семейка потомственных блядей и куколдов.: 0.0 1.0 0.0 0.0\n",
      "А этот коммент можете плюсовать: 0.0 0.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7fcab",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "Токсичность комментариев -- очень субъективная тема, особенно в рамках бинарной классификации. Кого-то может и вот такое задеть: ```\"хочешь грудь модератора?\"``` <s>(последний пример из списка выше)</s> <i>перезапустил все ячейки и результаты поменялись, но раньше этот пример там был. Надо приучить себя определять рандом сид.</i> Конечно, для такой задачи нужно бы иметь побольше классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2afa6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = (\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": MultinomialNB,\n",
    "        \"classifier_args\" : {},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": DecisionTreeClassifier,\n",
    "        \"classifier_args\" : {\"min_samples_split\":2, \"max_depth\":26, \"class_weight\": 'balanced'},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": RandomForestClassifier,\n",
    "        \"classifier_args\" : {\"min_samples_split\":2, \"max_depth\":26, \"class_weight\": 'balanced'},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b22efef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\tCountVectorizer\n",
      "F1:  0.8726114649681529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       959\n",
      "         1.0       0.90      0.85      0.87       483\n",
      "\n",
      "    accuracy                           0.92      1442\n",
      "   macro avg       0.91      0.90      0.91      1442\n",
      "weighted avg       0.92      0.92      0.92      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/venv/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\tCountVectorizer\n",
      "F1:  0.837108953613808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92       959\n",
      "         1.0       0.87      0.80      0.84       483\n",
      "\n",
      "    accuracy                           0.90      1442\n",
      "   macro avg       0.89      0.87      0.88      1442\n",
      "weighted avg       0.89      0.90      0.89      1442\n",
      "\n",
      "DecisionTreeClassifier\tCountVectorizer\n",
      "F1:  0.6359918200408998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.81      0.81       959\n",
      "         1.0       0.63      0.64      0.64       483\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.72      0.73      0.72      1442\n",
      "weighted avg       0.75      0.75      0.75      1442\n",
      "\n",
      "RandomForestClassifier\tCountVectorizer\n",
      "F1:  0.712166172106825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.82      0.84       959\n",
      "         1.0       0.68      0.75      0.71       483\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.79      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_experiments = []\n",
    "\n",
    "for d in experiment_params:\n",
    "    experiment = Experiment(**d)\n",
    "    print(f'{d[\"classifier_model\"].__name__}\\t{d[\"vectorizer_model\"].__name__}')\n",
    "    print(\"F1: \", experiment.get_f1())\n",
    "    print(experiment.get_report())\n",
    "    finished_experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a32602",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "<q>по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75</q>\n",
    "\n",
    "Кажется, такой возможности нет :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f86a77",
   "metadata": {},
   "source": [
    "#### Для дерева решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f85d3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "453c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(\n",
    "    {\n",
    "        token: importance\n",
    "        for token, importance\n",
    "        in zip(\n",
    "            finished_experiments[2].vectorizer.vocabulary_,\n",
    "            finished_experiments[2].classifier.feature_importances_\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c64741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(не ', np.float64(0.09549377153881515)),\n",
       " ('ят-ко', np.float64(0.07708447535110827)),\n",
       " ('редка', np.float64(0.06147589391657986)),\n",
       " ('недур', np.float64(0.033763387534206615)),\n",
       " ('ато.', np.float64(0.030857429719008116))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d12fe",
   "metadata": {},
   "source": [
    "#### Для леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cb27cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(\n",
    "    {\n",
    "        token: importance\n",
    "        for token, importance\n",
    "        in zip(\n",
    "            finished_experiments[3].vectorizer.vocabulary_,\n",
    "            finished_experiments[3].classifier.feature_importances_\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c596d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('орниш', np.float64(0.004847584581782989)),\n",
       " ('ема,', np.float64(0.004449736649807151)),\n",
       " (' (не', np.float64(0.004388843863988988)),\n",
       " ('ощал', np.float64(0.004067373274740722)),\n",
       " ('сс. ', np.float64(0.0037168778427236664))]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0ad23",
   "metadata": {},
   "source": [
    "#### Для наивного Байеса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "290627a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(\n",
    "    {\n",
    "        token: importance\n",
    "        for token, importance\n",
    "        in zip(\n",
    "            finished_experiments[0].vectorizer.vocabulary_,\n",
    "            finished_experiments[0].classifier.feature_log_prob_[1]\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04f807f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('коти', np.float64(-6.2147600948356345)),\n",
       " ('амые', np.float64(-6.2612959151249985)),\n",
       " ('actic', np.float64(-6.300294121741232)),\n",
       " ('щёбу ', np.float64(-6.3978120875995135)),\n",
       " ('лстр', np.float64(-6.4046107540585915))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379b0e5",
   "metadata": {},
   "source": [
    "#### Комментарий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fb30a",
   "metadata": {},
   "source": [
    "#### Для ЛогРега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(\n",
    "    {\n",
    "        token: importance\n",
    "        for token, importance\n",
    "        in zip(\n",
    "            finished_experiments[1].vectorizer.vocabulary_,\n",
    "            np.mean(np.abs(finished_experiments[1].classifier.coef_), axis=0)\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c7967bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' (не', np.float64(1.0883276543101839)),\n",
       " ('ят-ко', np.float64(1.041318533120039)),\n",
       " ('авае', np.float64(0.9627045670059449)),\n",
       " ('стит,', np.float64(0.9041365699664503)),\n",
       " ('репло', np.float64(0.8891025932143486))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
