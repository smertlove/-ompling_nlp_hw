{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eccc8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "    train.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vectorizer_model: object,\n",
    "            vectorizer_args : dict,\n",
    "            classifier_model: object,\n",
    "            classifier_args : dict\n",
    "        ):\n",
    "        \n",
    "        self.vectorizer = vectorizer_model(**vectorizer_args)\n",
    "        X = self.vectorizer.fit_transform(self.train.comment)\n",
    "        y = self.train.toxic.values\n",
    "\n",
    "        self.classifier = classifier_model(**classifier_args)\n",
    "        self.classifier.fit(X, y)\n",
    "\n",
    "    def get_test_preds(self):\n",
    "        X = self.vectorizer.transform(self.test.comment)\n",
    "        preds = self.classifier.predict(X)\n",
    "        return preds\n",
    "\n",
    "    def get_report(self):\n",
    "        return classification_report(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0\n",
    "        )\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return f1_score(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0        \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_default = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {},\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1be10bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.83       936\n",
      "         1.0       0.97      0.27      0.43       506\n",
      "\n",
      "    accuracy                           0.74      1442\n",
      "   macro avg       0.84      0.64      0.63      1442\n",
      "weighted avg       0.81      0.74      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_default.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dd3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71d0945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Если просто сунуть по ссылке, прилетает TypeError: '<' not supported between instances of 'Substring' and 'Substring'\n",
    "\n",
    "def odel_tokenize(text):\n",
    "    return [_.text for _ in razdel.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c556e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_razdel = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {\n",
    "        \"tokenizer\": odel_tokenize,\n",
    "        \"analyzer\" : \"word\"\n",
    "    },\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b06dc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      1.00      0.82       936\n",
      "         1.0       0.96      0.19      0.32       506\n",
      "\n",
      "    accuracy                           0.71      1442\n",
      "   macro avg       0.83      0.59      0.57      1442\n",
      "weighted avg       0.79      0.71      0.64      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_razdel.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f919aa1",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В документации Razdel написано, что\n",
    "\n",
    "<q>\n",
    "Правила в Razdel оптимизированы для аккуратно написанных текстов с правильной пунктуацией. Решение хорошо работает с новостными статьями, художественными текстами. На постах из социальных сетей, расшифровках телефонных разговоров качество ниже.\n",
    "</q>\n",
    "\n",
    "Поэтому неудивительно, что на данном датасете Razdel работает чуть хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = (\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": MultinomialNB,\n",
    "        \"classifier_args\" : {},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        ##  Здесь и далее наилучшие результаты давала векторизация с параметрами analyzer + ngram_range + max_df\n",
    "        ##  Т.е. с 3-мя вручную заданными параметрами, поэтому 2 отставшихся по заданию забил дефолтными.\n",
    "        ##  Иные вмешательства делали результат хуже.\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    ##  Фактически задание не выполнено т.к. в обоих случаях результаты получаются лучше с мешком слов.\n",
    "    ##  Однако вот такая конфигурация проходит только с варнингом, поэтому можно считать, что TF-IDF лучше т.к. стабильнее (?)\n",
    "    {   \n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": TfidfVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\tCountVectorizer\n",
      "F1:  0.8678861788617886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       936\n",
      "         1.0       0.89      0.84      0.87       506\n",
      "\n",
      "    accuracy                           0.91      1442\n",
      "   macro avg       0.91      0.89      0.90      1442\n",
      "weighted avg       0.91      0.91      0.91      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\tCountVectorizer\n",
      "F1:  0.8530318602261048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93       936\n",
      "         1.0       0.89      0.82      0.85       506\n",
      "\n",
      "    accuracy                           0.90      1442\n",
      "   macro avg       0.90      0.88      0.89      1442\n",
      "weighted avg       0.90      0.90      0.90      1442\n",
      "\n",
      "LogisticRegression\tTfidfVectorizer\n",
      "F1:  0.819672131147541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.92       936\n",
      "         1.0       0.92      0.74      0.82       506\n",
      "\n",
      "    accuracy                           0.89      1442\n",
      "   macro avg       0.90      0.85      0.87      1442\n",
      "weighted avg       0.89      0.89      0.88      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_experiments = []\n",
    "\n",
    "for d in experiment_params:\n",
    "    experiment = Experiment(**d)\n",
    "    print(f\"{d[\"classifier_model\"].__name__}\\t{d[\"vectorizer_model\"].__name__}\")\n",
    "    print(\"F1: \", experiment.get_f1())\n",
    "    print(experiment.get_report())\n",
    "    finished_experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc3ab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Для читаемости\n",
    "nb_bow_preds       = finished_experiments[0].get_test_preds()\n",
    "logreg_bow_preds   = finished_experiments[1].get_test_preds()\n",
    "logreg_tfidf_preds = finished_experiments[2].get_test_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7abe0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_normal_results      = []\n",
    "same_toxic_results       = []\n",
    "different_normal_results = []\n",
    "different_toxic_results  = []\n",
    "\n",
    "# for comment, is_toxic, nb_bow_pred, logreg_bow_pred, logreg_tfidf_pred \\\n",
    "for comment, results in zip(\n",
    "        Experiment.test.comment,\n",
    "        zip(\n",
    "            experiment.test.toxic,\n",
    "            nb_bow_preds,\n",
    "            logreg_bow_preds,\n",
    "            logreg_tfidf_preds\n",
    "        )\n",
    "    ):\n",
    "\n",
    "    elem_to_append = comment.strip() + \": \" + \" \".join(map(str, results))\n",
    "    if sum(results) in (0, 4):\n",
    "        if results[0] == 1:\n",
    "            same_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            same_normal_results.append(elem_to_append)\n",
    "    else:\n",
    "        if results[0] == 1:\n",
    "            different_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            different_normal_results.append(elem_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9775096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 863, 148, 73)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(same_toxic_results), len(same_normal_results), len(different_toxic_results), len(different_normal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "836e6e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Может верблюдов сжечь? Во славу и величие Израиля, к примеру.: 1.0 1.0 1.0 1.0\n",
      "лол, вафлёрные зоошизики меня минусуют) пздц убогие: 1.0 1.0 1.0 1.0\n",
      "Моему бате отвалилось и упало на голову. Кровища была, потом шишка осталась (да, я сволочь ): 1.0 1.0 1.0 1.0\n",
      "Он платить за хохлов не будет.: 1.0 1.0 1.0 1.0\n",
      "ты заткнуться можешь?: 1.0 1.0 1.0 1.0\n",
      "Я вам хамил? Я это не заметил. Или это из серии ажемать яжотец яжбэмэвэ?: 1.0 1.0 1.0 1.0\n",
      "Прям, как в песне группы DZIDZIO Павук З ла лахудра Бодьку-павука. А мораль такова з ла баба мужика!: 1.0 1.0 1.0 1.0\n",
      "Высирается твоя мамаша тебе на лицо по утрам, а я высказался, обессилев от негодования от засравших политач ловцов лахты под кроватью.: 1.0 1.0 1.0 1.0\n",
      "Слишком, блядь, мощно: 1.0 1.0 1.0 1.0\n",
      "мааам, меня обидили, почему я дегенерат, мам?: 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "427fcf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Причем тут латынь? Есть название на русском языке, современное и устоявщееся и подкрепленное современной докумениацией этой страны.. По какой-то причине в других языках называют города не транслитизированным переносом, а как-то иначе. Если это общепринятые нормы, то почему надо спорить ламборгини или ламборджини, если это общепринятая норма?: 0.0 0.0 0.0 0.0\n",
      "Вот зря вы. У нас по сравнению с США огромный опыт работы с орбитальными станциями (доставка грузов космонавтов, постройка и обслуживание станций и т.д.) и огромный опыт по космическим кораблям. Да, многие технологии сейчас уже давно впереди (вычислительные, ПО и т.п.). Но если совместить наш опыт с технологиями зарубежных стран, то получиться реально стоящие косм. корабли и косм. станции, благодаря которым человечество будет спокойно осваивать другие планеты и их спутники. Но опять же, мы ни при каких условиях с кем-то работать не будем, ибо этот огромный опыт, который мы передадим -- может пойти не в то русло. Так что если если и будем участвовать, то скорее всего так: Вот мы для вас КК сделали как вы просили, вот на нём и полетите .: 0.0 0.0 0.0 0.0\n",
      "Ну 1 из 6 есть, уже неплохо: 0.0 0.0 0.0 0.0\n",
      "а движку на это пофигу? а то не хотелось бы на ремонт попасть. А помыть не проблема.: 0.0 0.0 0.0 0.0\n",
      "В доллары перевести и пускай будет запас на чёрный день. Ну а в остальном жить как жил, особо не трепаться и бабки не спускать. Всё равно лям рублей - это не бог весть какая сумма уже. Конечно большая, но уже не той ценности, что скажем в нулевых. Хотя деньги одни и те же с 1997 года. Особо кутить один хуй не выйдет, до конца жизни тоже не растянуть, чтобы жить по середнячку. Даже бомжевать не получится. Если толку нет куда-то вкладывать и извлекать прибыль, то это именно неплохая подушка безопасности.: 0.0 0.0 0.0 0.0\n",
      "Это норма для мужиков. Большие соски - признак смещения гормонального баланса. Потенциальное гино уже. И по совершенно случайному совпадению владельцы больших сосков так же являются гордыми обладателями сисек. В общем, гоните большесосок, насмехайтесь над ними.: 0.0 0.0 0.0 0.0\n",
      "Интересно было бы получить ответ.: 0.0 0.0 0.0 0.0\n",
      "Там атмосфера намного плотнее. Так что ураган будет с меньшей скорости начинаться.: 0.0 0.0 0.0 0.0\n",
      "Где этот город, в котором за 60к можно работать на одной работе? Тут на 3 ишачишь, и 50к еле еле: 0.0 0.0 0.0 0.0\n",
      "это коммерческие компании, что такого в этих цифрах?: 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "029df7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Забыл добавить , если при этом чурка пожизненно в сибири ,лес валить!: 1.0 1.0 0.0 0.0\n",
      "Беда в том, что полиции почему-то похуй на это быдлана Он сам по себе довольно таки темный в плане дел с законом. Не знаю, правда правое дело делает или там огромная крыша, но полиция так и не будет его трогать.: 1.0 0.0 1.0 0.0\n",
      "В те времена и мотобайкеров - рокерами называли...: 1.0 0.0 0.0 0.0\n",
      "Шинка, ты чего без аватарки сегодня?: 1.0 0.0 1.0 1.0\n",
      "Да всё гораздо проще. Плешивый карлан интересами граждан никогда не интересовался. Отсюда ебовый обвал рубля, чтобы холопы батрахили за зп в 2 раза меньше, чем раньше. Отмена пенсий (батрачить 40 лет, чтобы 4 года получать пенсию). Вот уже начал на интернет замахиваться, чтобы ради безопасности граждан они получали только одобренную режимом информацию. Настоящий анон, всегда был на своей стороне. Ему всегда было похуй на ракеты. Анон свободолюбив даже сидя у мамки на шее. Так что за плешивого карлика могут топить только враги анона, которые сидят тут на зарплате. А то, что ньюсач в частности и харкач в целом это одна из площадок для манипуляции общественным мнением - уже давно ни для кого не секрет. Т.е. даже ради троллинга тупостью анон никогда не будет защищать интересы того, что пытается забрать единственную отдушину в его жизни - интернет. Отсюда вывод, что если ты топишь за карлика и сочувствующих ему - ты лахтодырка на зарплате. У тебя отниму интернет - ты нихуя не потеряешь, пойдешь обратно ящик смотреть с киселем и соловьевым.: 1.0 1.0 1.0 0.0\n",
      "Знаете, моя подруга живёт с мужчиной, который вероятней всего ей изменял (переписки разрывала какие-то, но он оправдался, что это были только переписки и до встречи не дошло), который за 5 лет совместной жизни не знает, что такое квартплата и затраты на ребёнка (от предыдущего брака подруги), только через 2 года совместной жизни он узнал, что такое купить продукты в дом, который считает мнение своей мамы важнее всех на свете, который сделал предложение через скандал, женился через скандал (тайно), рассказал своим родителям через скандал и в период ожидания совместного ребёнка в квартире с недоделанным ремонтом (проштробленные стены, бетонный потолок) решил, что купит себе шестёрку и будет её чинить и дрифтовать. При этом за пять лет я уже устала слушать, какой он козёл, сволочь, подонок, ему ничего не надо, он ничего не хочет и так далее, скандалы, интриги, расследования. Моё мнение: если мужик - козёл, что ж ты с ним живёшь. Либо признавай, что сама дура и прекращай ныть, либо уходи и будь с нормальным мужиком. При этом её мнение: это любоф, я ничего не понимаю и она научит меня, как женить на себе мужика и как вообще жить семейной жизнью. Вторая подруга платит кредиты за бывшего мужа до сих пор. Мой единственный вывод: бабы очень часто дуры. Честно. Вот в жизни умные и профессионалы в своей сфере, и на жизнь вроде смотрят здраво, а в отношениях - дуры. Потому что вдолбили себе в голову, что если это любоф, то всё - нужно нести этот крест и позволять все что угодно в свой адрес. При этом муж первой - совсем иначе вёл себя с предыдущей пассией. Да и по жизни инфантилен несколько, но не такой уж козёл. И мозги таки есть. Бывший муж второй - тоже неплохой человек, но при жене, которая неделями не появляется дома, пашет на трех работах и получает в три раза больше него, так как профессия и признание на работе важнее всего остального - расслабился и ножки свесил. Просто каждый сам в ответе за свою жизнь. И я вижу очень много примеров, как женщины считают нормой в семье то, что с моей точки зрения совсем ненормально и неприемлемо. И они свято в это верят. Я не оправдываю мужиков и не обвиняю женщин, но если тебе с кем-то жить хреново - зачем ты с этим человеком живёшь. Если тебе от отношений что-то нужно, ты готов что-то делать, искать компромиссы, а твой партнёр класть на это все хотел - зачем тебе такие отношения. А я отвечу зачем - потому что очень часто девочкам вбивается, что если ты без мужика - ататата, если диточек не настрогала - атата, если ты одна - значит, ты несчастна. Итог - бежит женщина, хватается за кого-то и держится, и думает про себя - пофиг, что несчастна, зато с мужиком в отличие от этих несостоявшихся. Или в работу с головой уходит, чтобы не ввязываться в эту эпопею с отношениями, где все медленно рушится, если не уделять времени и внимания. Итог в обоих случаях плачевен. И да, обе подруги во время первого брака пытались научить меня, как выйти замуж и жить счастливо на своём примере. Обе в разводе и в браке во второй раз. Но это все большое отступление от темы, да. А мысль общая такая - если женщина любит не только своего мужчину, но и себя, и ценит себя - не будет она сидеть в луже говенных отношений, на работе тоже пропадать не будет и мужчину своего давить под каблуком не будет. Да, от мужчины зависит многое, но не всё - да, если мужчина тоже любит свою женщину, ценит себя и её - все у них будет хорошо. Плюсом, именно от женщины больше зависит - в какой обстановке будет расти ребёнок. Будет ли он впитывать пример отца и кто вообще будет отцом этого ребёнка. А значит - от женщины больше зависит, каким будет следующее поколение. У мужчин немного другая роль в этой пьесе, но именно от женщины зависит, будет ли размножаться и воспитывать жертву неадекват тиран тряпка истерик и так далее. И вот эта ответственность меня лично немного гнетет и заставляет предъявлять повышенные требования именно к себе, как к представительнице женского пола.: 1.0 0.0 0.0 0.0\n",
      "Допустим гомикадзе действительно заднеприводный. Это хоть на йоту оправдывает, допустим, повышение пенс. возраста? Тип если пидоры начнут выступать против всего плохого - то нормальные люди должны быть против всего хорошего? нет слава христу зиг хайль: 1.0 1.0 1.0 0.0\n",
      "Фррррр ПУК-ПУК По фактам есть что сказать, дикарь?: 1.0 1.0 0.0 0.0\n",
      "ищу коммент про нарушение тб: 1.0 0.0 1.0 0.0\n",
      "Да и ладно, зато хоть на женщину похожа, а не на швабру с костями...: 1.0 1.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac6b7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ряженые кизяки Извинись!: 0.0 1.0 1.0 1.0\n",
      "Носить телесные носки. Неграм проще.: 0.0 0.0 1.0 0.0\n",
      "Военные Базы!!!!!!! Ты что не понимаишь!!!!!! Военные!!!!!!!!! Кругом война! Никаких прочих идей не существует. А в школе - вам нагло врут!: 0.0 1.0 1.0 1.0\n",
      "I believe I can touch the sky: 0.0 1.0 0.0 0.0\n",
      "хохохо, а ты хорош! В: 0.0 1.0 1.0 1.0\n",
      "Как что-то плохое. после фоток Бэллы ИТТ хоть будет на что потилибонькать: 0.0 1.0 0.0 0.0\n",
      "Аааа, ясно как ты знаешь США, наверное по твоему тут и негров линчуют А я своими глазами видел в прошлом году гей парад, который не то что разгоняли, там участвовали геи-копы, геи-политики, геи-пожарные, геи-медики итп Поэтому не вижу смысла продолжать спорить с человеком, который знает об Америке только с заголовков газет, лучше полюбуйся на фотки гей парадов в США на которых я был: 0.0 1.0 1.0 1.0\n",
      "Нихуя, забытый. Он недавно лям собрал: 0.0 1.0 0.0 1.0\n",
      "http: www.aspd.ru napravlenija dejatelnosti akusticheskie-materialy akusticheskaja rezina gsp 100 vibrozaschita: 0.0 1.0 0.0 0.0\n",
      "Ага, тред тоже был потерт без объяснений.: 0.0 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7fcab",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "Токсичность комментариев -- очень субъективная тема, особенно в рамках бинарной классификации. Кого-то может и вот такое задеть: ```\"хочешь грудь модератора?\"``` <s>(последний пример из списка выше)</s> <i>перезапустил все ячейки и результаты поменялись, но раньше этот пример там был. Надо приучить себя определять рандом сид.</i> Конечно, для такой задачи нужно бы иметь побольше классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2afa6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = (\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": MultinomialNB,\n",
    "        \"classifier_args\" : {},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": DecisionTreeClassifier,\n",
    "        \"classifier_args\" : {},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": RandomForestClassifier,\n",
    "        \"classifier_args\" : {\"n_estimators\": 10},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b22efef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\tCountVectorizer\n",
      "F1:  0.8678861788617886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       936\n",
      "         1.0       0.89      0.84      0.87       506\n",
      "\n",
      "    accuracy                           0.91      1442\n",
      "   macro avg       0.91      0.89      0.90      1442\n",
      "weighted avg       0.91      0.91      0.91      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\tCountVectorizer\n",
      "F1:  0.8530318602261048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93       936\n",
      "         1.0       0.89      0.82      0.85       506\n",
      "\n",
      "    accuracy                           0.90      1442\n",
      "   macro avg       0.90      0.88      0.89      1442\n",
      "weighted avg       0.90      0.90      0.90      1442\n",
      "\n",
      "DecisionTreeClassifier\tCountVectorizer\n",
      "F1:  0.6915113871635611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.84       936\n",
      "         1.0       0.73      0.66      0.69       506\n",
      "\n",
      "    accuracy                           0.79      1442\n",
      "   macro avg       0.78      0.76      0.77      1442\n",
      "weighted avg       0.79      0.79      0.79      1442\n",
      "\n",
      "RandomForestClassifier\tCountVectorizer\n",
      "F1:  0.635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.96      0.86       936\n",
      "         1.0       0.86      0.50      0.64       506\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.82      0.73      0.75      1442\n",
      "weighted avg       0.81      0.80      0.78      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_experiments = []\n",
    "\n",
    "for d in experiment_params:\n",
    "    experiment = Experiment(**d)\n",
    "    print(f\"{d[\"classifier_model\"].__name__}\\t{d[\"vectorizer_model\"].__name__}\")\n",
    "    print(\"F1: \", experiment.get_f1())\n",
    "    print(experiment.get_report())\n",
    "    finished_experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da11180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
