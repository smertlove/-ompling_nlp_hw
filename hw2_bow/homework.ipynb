{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eccc8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment(vectorizer: TfidfVectorizer, train:pd.DataFrame, test:pd.DataFrame):\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train.comment)\n",
    "    y_train = train.toxic.values\n",
    "\n",
    "    X_test  = vectorizer.transform(test.comment)\n",
    "    y_test  = test.toxic.values\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    preds = classifier.predict(X_test)\n",
    "\n",
    "    return classification_report(y_test, preds, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      1.00      0.85       973\n",
      "         1.0       0.97      0.28      0.44       469\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.86      0.64      0.64      1442\n",
      "weighted avg       0.82      0.76      0.72      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment(\n",
    "        TfidfVectorizer(),\n",
    "        train,\n",
    "        test,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dd3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71d0945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Если просто сунуть по ссылке, прилетает TypeError: '<' not supported between instances of 'Substring' and 'Substring'\n",
    "\n",
    "def odel_tokenize(text):\n",
    "    return [_.text for _ in razdel.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b06dc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      1.00      0.84       973\n",
      "         1.0       0.99      0.23      0.37       469\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.86      0.61      0.61      1442\n",
      "weighted avg       0.81      0.75      0.69      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment(\n",
    "        TfidfVectorizer(tokenizer=odel_tokenize, analyzer=\"word\"),\n",
    "        train,\n",
    "        test,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f919aa1",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В документации Razdel написано, что\n",
    "\n",
    "<q>\n",
    "Правила в Razdel оптимизированы для аккуратно написанных текстов с правильной пунктуацией. Решение хорошо работает с новостными статьями, художественными текстами. На постах из социальных сетей, расшифровках телефонных разговоров качество ниже.\n",
    "</q>\n",
    "\n",
    "Поэтому неудивительно, что на данном датасете Razdel работает чуть хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90311fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
