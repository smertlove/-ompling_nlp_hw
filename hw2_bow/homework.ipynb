{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eccc8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "    train.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vectorizer_model: object,\n",
    "            vectorizer_args : dict,\n",
    "            classifier_model: object,\n",
    "            classifier_args : dict\n",
    "        ):\n",
    "        \n",
    "        self.vectorizer = vectorizer_model(**vectorizer_args)\n",
    "        X = self.vectorizer.fit_transform(self.train.comment)\n",
    "        y = self.train.toxic.values\n",
    "\n",
    "        self.classifier = classifier_model(**classifier_args)\n",
    "        self.classifier.fit(X, y)\n",
    "\n",
    "    def get_test_preds(self):\n",
    "        X = self.vectorizer.transform(self.test.comment)\n",
    "        preds = self.classifier.predict(X)\n",
    "        return preds\n",
    "\n",
    "    def get_report(self):\n",
    "        return classification_report(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0\n",
    "        )\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return f1_score(\n",
    "            self.test.toxic.values,\n",
    "            self.get_test_preds(),\n",
    "            zero_division=0        \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_default = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {},\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1be10bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.99      0.85       977\n",
      "         1.0       0.94      0.25      0.40       465\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.84      0.62      0.62      1442\n",
      "weighted avg       0.80      0.75      0.70      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_default.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2dd3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "71d0945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Если просто сунуть по ссылке, прилетает TypeError: '<' not supported between instances of 'Substring' and 'Substring'\n",
    "\n",
    "def odel_tokenize(text):\n",
    "    return [_.text for _ in razdel.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c556e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_razdel = Experiment(\n",
    "    TfidfVectorizer,\n",
    "    {\n",
    "        \"tokenizer\": odel_tokenize,\n",
    "        \"analyzer\" : \"word\"\n",
    "    },\n",
    "    MultinomialNB,\n",
    "    {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b06dc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.99      0.83       977\n",
      "         1.0       0.93      0.17      0.29       465\n",
      "\n",
      "    accuracy                           0.73      1442\n",
      "   macro avg       0.82      0.58      0.56      1442\n",
      "weighted avg       0.79      0.73      0.66      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    experiment_razdel.get_report()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f919aa1",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В документации Razdel написано, что\n",
    "\n",
    "<q>\n",
    "Правила в Razdel оптимизированы для аккуратно написанных текстов с правильной пунктуацией. Решение хорошо работает с новостными статьями, художественными текстами. На постах из социальных сетей, расшифровках телефонных разговоров качество ниже.\n",
    "</q>\n",
    "\n",
    "Поэтому неудивительно, что на данном датасете Razdel работает чуть хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params = (\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": MultinomialNB,\n",
    "        \"classifier_args\" : {},  ##  Чудесным образом любое вмешательство в парамеры сильно ухудшает результаты\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        ##  Здесь и далее наилучшие результаты давала векторизация с параметрами analyzer + ngram_range + max_df\n",
    "        ##  Т.е. с 3-мя вручную заданными параметрами, поэтому 2 отставшихся по заданию забил дефолтными.\n",
    "        ##  Иные вмешательства делали результат хуже.\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    ##  Фактически задание не выполнено т.к. в обоих случаях результаты получаются лучше с мешком слов.\n",
    "    ##  Однако вот такая конфигурация проходит только с варнингом, поэтому можно считать, что TF-IDF лучше т.к. стабильнее (?)\n",
    "    {   \n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": CountVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"classifier_model\": LogisticRegression,\n",
    "        \"classifier_args\" : {\"solver\":\"liblinear\", \"penalty\":\"l2\"},\n",
    "        \"vectorizer_model\": TfidfVectorizer,\n",
    "        \"vectorizer_args\" : {\"analyzer\": \"char_wb\",\"ngram_range\": (3, 5), \"max_df\": 0.48, \"encoding\":\"utf-8\", \"input\":\"content\"}\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\tCountVectorizer\n",
      "F1:  0.8549107142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       977\n",
      "         1.0       0.89      0.82      0.85       465\n",
      "\n",
      "    accuracy                           0.91      1442\n",
      "   macro avg       0.90      0.89      0.89      1442\n",
      "weighted avg       0.91      0.91      0.91      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HSE subj data\\актуальные проблемы компьютерной лингвистики\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\tCountVectorizer\n",
      "F1:  0.843400447427293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       977\n",
      "         1.0       0.88      0.81      0.84       465\n",
      "\n",
      "    accuracy                           0.90      1442\n",
      "   macro avg       0.90      0.88      0.89      1442\n",
      "weighted avg       0.90      0.90      0.90      1442\n",
      "\n",
      "LogisticRegression\tTfidfVectorizer\n",
      "F1:  0.8133971291866029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92       977\n",
      "         1.0       0.92      0.73      0.81       465\n",
      "\n",
      "    accuracy                           0.89      1442\n",
      "   macro avg       0.90      0.85      0.87      1442\n",
      "weighted avg       0.89      0.89      0.89      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_experiments = []\n",
    "\n",
    "for d in experiment_params:\n",
    "    experiment = Experiment(**d)\n",
    "    print(f\"{d[\"classifier_model\"].__name__}\\t{d[\"vectorizer_model\"].__name__}\")\n",
    "    print(\"F1: \", experiment.get_f1())\n",
    "    print(experiment.get_report())\n",
    "    finished_experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bc3ab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Для читаемости\n",
    "nb_bow_preds       = finished_experiments[0].get_test_preds()\n",
    "logreg_bow_preds   = finished_experiments[1].get_test_preds()\n",
    "logreg_tfidf_preds = finished_experiments[2].get_test_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7abe0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_normal_results      = []\n",
    "same_toxic_results       = []\n",
    "different_normal_results = []\n",
    "different_toxic_results  = []\n",
    "\n",
    "# for comment, is_toxic, nb_bow_pred, logreg_bow_pred, logreg_tfidf_pred \\\n",
    "for comment, results in zip(\n",
    "        Experiment.test.comment,\n",
    "        zip(\n",
    "            experiment.test.toxic,\n",
    "            nb_bow_preds,\n",
    "            logreg_bow_preds,\n",
    "            logreg_tfidf_preds\n",
    "        )\n",
    "    ):\n",
    "\n",
    "    elem_to_append = comment.strip() + \": \" + \" \".join(map(str, results))\n",
    "    if sum(results) in (0, 4):\n",
    "        if results[0] == 1:\n",
    "            same_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            same_normal_results.append(elem_to_append)\n",
    "    else:\n",
    "        if results[0] == 1:\n",
    "            different_toxic_results.append(elem_to_append)\n",
    "        else:\n",
    "            different_normal_results.append(elem_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a9775096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 905, 142, 72)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(same_toxic_results), len(same_normal_results), len(different_toxic_results), len(different_normal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "836e6e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!: 1.0 1.0 1.0 1.0\n",
      "Короче типичное гиперкомпенсаторство от малых народов-неудачников И дрочь на нацистскую германию это просто эталонный признак даунов-аутистов, для которых эстетика важнее мозга и своей культуры.: 1.0 1.0 1.0 1.0\n",
      "Павел Михайловский казалось бы, причём здесь хохлы: 1.0 1.0 1.0 1.0\n",
      "А я бы сдал Путина, согласятся ли хохлы получить Путина и отказаться от Крыма?: 1.0 1.0 1.0 1.0\n",
      "Красавчик, надеюсь свалит за бугор и продолжит шатать пидорашкку изнутри и ставить Ванек на путь истинный.: 1.0 1.0 1.0 1.0\n",
      "И зачем в сноске эти откровения Не виляй жопой, челядь. Твоя претензия была к тому, что ссылка якобы взята из непроверенного источника, во что я тебя и ткнул твоей неумытой харей. Ты пойман за руку как подлец и дешевка.: 1.0 1.0 1.0 1.0\n",
      "Ну и тебя тоже к стенке. Лично пулю в лоб всажу, ибо ну их в жопу ваши революции , наелась ими уже страна.: 1.0 1.0 1.0 1.0\n",
      "Котенок не блевотина же.: 1.0 1.0 1.0 1.0\n",
      "Хлеб, жуть, пережатое, перемятое, пинает старого пьяного койота, петух в унитазе кукарекает,: 1.0 1.0 1.0 1.0\n",
      "Да насрать на наципрезика и иже с ними: 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "427fcf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Там гайка была под ключ на 17 и затягивалась с такой силой, что контакт никогда не пропадал. Лично у меня не бывало таких проблем. Но теоретически, они могут возникнуть. Вот одна из схем, которые мне дал яндекс, четко видно, что сначала на стартер идет, а потом уже дальше.: 0.0 0.0 0.0 0.0\n",
      "А я так фанатела от орифлеймовских духов, стоили они аж 1200 рублей, а пахли пудрой. Тоже уже не производят, увы(: 0.0 0.0 0.0 0.0\n",
      "Один кондей дешевле чем каналка. Мощности только на номер а не на всех здание в холостую: 0.0 0.0 0.0 0.0\n",
      "Есть ощущение, что мое рабочее здание из Окленда. Крыша течет, вода по стенам, везде плесень. А ведь ремонт 6 лет назад сделали на 5 лимонов, мля. И все сроки исправления оттянули до невзврата, суки. Все, кто сюда приходят, постоянно болеют давлением, достаточно прийти с простудой, чтобы заразились все посетители, посидевшие у нас пару часов.: 0.0 0.0 0.0 0.0\n",
      "У этих людей работа такая. Ну и средств получения информации гораздо больше чем у рядового, да даже не рядового, следователя. Однако они и мелочью не занимаются, решают проблемы других порядков.: 0.0 0.0 0.0 0.0\n",
      "Затраты издателя в пересчете на одну книгу на порядки меньше, чем с бумажными.: 0.0 0.0 0.0 0.0\n",
      "Как там говорят: Да херня! С одной дозы (рюмки, сигаретки) ничего не будет! Мы свою меру знаем. У нас отличная культура потребления (питья и прочее). Захочу - в любой момент брошу!: 0.0 0.0 0.0 0.0\n",
      "ну да, New Dawn, но все же поняли о чём идёт речь.: 0.0 0.0 0.0 0.0\n",
      "простите за простыню, в дороге скучно) Одна моя одногрупница считала, что заводы с ощутимым продуктом - единственный стоящий нормальный бизнес. Но, если посмотреть на богатые страны, доля сферы услуг там выше, чем в странах бедных. И это правильно. Вообще, движение денег движет экономику. В СССР считалось, что спекулянты - это аморально. Но что делает спекулянт? Он перепродает - дает потребителю пощупать товар, дает гарантию, перевозит товар из точки А в точку Б. И это хорошо. Для бизнеса добавленная стоимость - это прибыль. Бизнес бывает разный - услуги, производство, торговля. Если не считать всякие схемы с откатами, и прочее искусственное повышение стоимости (как при монополии), бизнес старается сделать цену, по которой он получает максимум прибыли, при которой у него готовы покупать. Бизнес банкротится, если не может поддерживать цену ниже конкурентов, из-за, например, слишком высоких издержек, или потому что в стране А налоги в 2 раза выше, чем в стране Б. Ну, или ставит высокую цену и упирает на качество. Бизнес - это любая хозяйственная деятельность, направленная на получение прибыли. Нет полезной деятельности нет прибыли.: 0.0 0.0 0.0 0.0\n",
      "Потому что нет тега моё и указан источник, откуда были взяты фотографии.: 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in same_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "029df7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скажите участковому, он её застрелит.: 1.0 0.0 0.0 0.0\n",
      "До чего же ельцинская банда довела дороги в городке...: 1.0 0.0 1.0 0.0\n",
      "А девушек-сумоисток жирдяй-тян? :-): 1.0 1.0 0.0 0.0\n",
      "Ну а что такого то? Ясен хуй если он завел трактор то особой любви к рашке он не испытывал. Высказывает свое мнение. Все правильно говорит. Разбил розовые очки в один прекрасный день и увидел все как есть. Что он не так написал? Что люди тут друг друга не ненавидят? Все правильно пишет. Целиком читать не буду, мне времени жалко.: 1.0 1.0 1.0 0.0\n",
      "А вы похоже тоже из этих? Не буду, пожалуй, вам ничего писать, вдруг вы заразны.: 1.0 0.0 0.0 0.0\n",
      "Да, на Rust е ЯП были примеры задач по этому тупому примеру.: 1.0 0.0 1.0 0.0\n",
      "Долбоеб, это молоко для веганов и тех у кого непереносимость лактозы. В ваших колхозах про веганов слышали вообще? Хотя кого я спрашиваю, нищий чубатый деревенщина, ничего сложнее сала не видел. И кстати эта хуйня стоит дороже обычного молока, охуеть да?: 1.0 1.0 1.0 0.0\n",
      "гнильем скотину кормить? Скорее чтоб не намокло упаковали сухое сено: 1.0 0.0 1.0 0.0\n",
      "кикбоксера хана Батыя руководить Калмыкией -Бату Хасиков, у нас тут регион пустеет, нужно решить проблему с безработицей и трудоустройством. -Тебе че, в ебыч прописать? Ты мой заместитель или чей? Вот и пиздуй работать. - Я уже согласовал со всеми отделами план вывода региона из кризиса, нужно чтоб вы посмотрели и поставили подпись. - Че это за таблицы? А это что за цифра? Пиши понятным языком, а то защеку тебе щяс подпись поставлю.: 1.0 0.0 1.0 0.0\n",
      "а как этой лентой шлейф отпаянный чинить ? ( Z-Axis Conductive Tape iPod Touch Ribbon Fix): 1.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_toxic_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ac6b7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первая заявка на победу в треде! Кемерово теперь славный город Пыня. Если появится другой претендендент - Кемерово станет Пыня-1, закрытое территориальное образование по типу Челябинска-40.: 0.0 1.0 1.0 0.0\n",
      "Да не торопись ты так, бабуль: 0.0 1.0 1.0 1.0\n",
      "А что, до 05.11.17 кто-то другой это смотрел?: 0.0 1.0 0.0 0.0\n",
      "Мне Вас очень жаль, если для Вас оскорбления - норма.: 0.0 1.0 1.0 0.0\n",
      "Краска с радиопоглащением, которой окрашен самолёт будет мешать радару с фазированной решеткой: 0.0 0.0 1.0 0.0\n",
      "Горький так выступал за диктатуру пролетариата, а когда она началась ему почему-то захотелось жить на загнивающем Западе.: 0.0 1.0 1.0 0.0\n",
      "Пока гром не грянет мужик не перекрестится.: 0.0 1.0 0.0 0.0\n",
      "Извини тебе в грязном ходить приятно?: 0.0 1.0 1.0 1.0\n",
      "Если мы не сделаем снеговик, его сделают солдаты НАТО!: 0.0 1.0 1.0 1.0\n",
      "хочешь грудь модератора?: 0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for c in different_normal_results[:10]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7fcab",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "Токсичность комментариев -- очень субъективная тема, особенно в рамках бинарной классификации. Кого-то может и вот такое задеть: ```\"хочешь грудь модератора?\"``` (последний пример из списка выше). Конечно, для такой задачи нужно бы иметь побольше классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
