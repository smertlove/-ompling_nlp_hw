{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c678e33-7efc-47da-bd84-890daf4b5beb",
   "metadata": {},
   "source": [
    "# Задание 1 (4 балла)\n",
    "\n",
    "Имплементируйте алгоритм Леска (описание есть в семинаре) и оцените качество его работы на датасете `data/corpus_wsd_50k.txt`\n",
    "\n",
    "В качестве метрики близости вы должны попробовать два подхода:\n",
    "\n",
    "1) Jaccard score на множествах слов (определений и контекста)\n",
    "2) Cosine distance на эмбедингах sentence_transformers\n",
    "\n",
    "В качестве метрики используйте accuracy (% правильных ответов). Предсказывайте только многозначные слова в датасете\n",
    "\n",
    "Контекст вы можете определить самостоятельно (окно вокруг целевого слова или все предложение). Также можете поэкспериментировать с предобработкой для обоих методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5814a100-9ba8-4787-b0ac-73fa657a3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Загрузка датасета\n",
    "import pathlib\n",
    "\n",
    "corpus_path = pathlib.Path(r\"data/corpus_wsd_50k.txt\")\n",
    "with open(corpus_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    corpus = file.read().split('\\n\\n')\n",
    "    corpus = map(\n",
    "        lambda sent: [\n",
    "            word.split(\"\\t\")\n",
    "            for word\n",
    "            in sent.split(\"\\n\")\n",
    "            ],\n",
    "        corpus\n",
    "        )\n",
    "    corpus = tuple(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a3cfdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'what', 'What'],\n",
       " ['effort%1:04:00::', 'effort', 'effort'],\n",
       " ['', 'do', 'do'],\n",
       " ['', 'you', 'you'],\n",
       " ['make%2:41:00::', 'make', 'make'],\n",
       " ['', 'to', 'to'],\n",
       " ['assess%2:31:00::', 'assess', 'assess'],\n",
       " ['result%1:11:00::', 'result', 'results'],\n",
       " ['', 'of', 'of'],\n",
       " ['', 'you', 'your'],\n",
       " ['program%1:09:01::', 'program', 'program'],\n",
       " ['', '?', '?']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cbeefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kirill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe114c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bff1543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effort earnest and conscientious activity intended to do or accomplish something\n",
      "make engage in\n",
      "assess evaluate or estimate the nature, quality, ability, extent, or significance of\n",
      "result something that results\n",
      "program a system of projects or services intended to meet a public need\n"
     ]
    }
   ],
   "source": [
    "for word in corpus[2]:\n",
    "    if word[0]:\n",
    "\n",
    "        defn = wn.lemma_from_key(word[0]).synset().definition()\n",
    "        print(word[1], defn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efde9a-af0b-4c94-bfd0-249e7054562f",
   "metadata": {},
   "source": [
    "# Задание 2 (4 балла)\n",
    "Попробуйте разные алгоритмы кластеризации на датасете - `https://github.com/nlpub/russe-wsi-kit/blob/initial/data/main/wiki-wiki/train.csv`\n",
    "\n",
    "Используйте код из семинара как основу. Используйте ARI как метрику качества.\n",
    "\n",
    "Попробуйте все 4 алгоритма кластеризации, про которые говорилось на семинаре. Для каждого из алгоритмов попробуйте настраивать гиперпараметры (посмотрите их в документации). Прогоните как минимум 5 экспериментов (не обязательно успешных) с разными параметрами на каждый алгоритме кластеризации и оцените: качество кластеризации, скорость работы, интуитивность параметров.\n",
    "\n",
    "Помимо этого также выберите 1 дополнительный алгоритм кластеризации отсюда - https://scikit-learn.org/stable/modules/clustering.html , опишите своими словами принцип его работы  и проделайте аналогичные эксперименты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bef3e-1af7-4ce2-b43a-dfef282050f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
