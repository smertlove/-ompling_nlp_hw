{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fc8290",
   "metadata": {},
   "source": [
    "## Задание 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a5ace",
   "metadata": {},
   "source": [
    "Посчитайте частоты для 5-грамм в корпусе lenta.txt. двумя способами:  \n",
    "1) lenta.txt -> sent_tokenize (russian) -> word_tokenize -> ngrammer  \n",
    "2) lenta.txt -> word_tokene(preserve_line=True) - ngrammer  \n",
    "    \n",
    "Проанализируйте топ-20 самых частотных нграмм и проверьте есть ли различия? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfe6a96-b23b-41a0-b7b9-1d9f974dfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/lenta.txt\"\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957f5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe4951e-7406-4601-a943-71b87b3b1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = sent_tokenize(data, language='russian')\n",
    "sentences1 = [word_tokenize(sentence) for sentence in sentences1]\n",
    "sentences1 = [\n",
    "    [token.lower() for token in sentence if not re.match(r'\\W+', token)] \n",
    "    for sentence in sentences1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0566988d-6d3d-4636-bc05-1cfa589a44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def get_20_most_common(sentences, n):\n",
    "    counter = Counter()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        counter.update(ngrammer(sentence, n))\n",
    "    \n",
    "    return counter.most_common(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c72eb3-96a2-46fb-bdde-910290e306aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('риа новости со ссылкой на', 400),\n",
       " ('сообщает риа новости со ссылкой', 320),\n",
       " ('как сообщили риа новости в', 196),\n",
       " ('как сообщает риа новости со', 149),\n",
       " ('сообщает интерфакс со ссылкой на', 142),\n",
       " ('сообщает итар-тасс со ссылкой на', 118),\n",
       " ('об этом риа новости сообщили', 113),\n",
       " ('об этом сообщает риа новости', 104),\n",
       " ('этом риа новости сообщили в', 99),\n",
       " ('со ссылкой на источники в', 93),\n",
       " ('сообщили риа новости в пресс-службе', 88),\n",
       " ('группировки войск на северном кавказе', 84),\n",
       " ('как сообщает интерфакс со ссылкой', 83),\n",
       " ('объединенной группировки войск на северном', 83),\n",
       " ('новости со ссылкой на пресс-службу', 76),\n",
       " ('эхо москвы со ссылкой на', 76),\n",
       " ('этом сообщает риа новости со', 75),\n",
       " ('в связи с тем что', 70),\n",
       " ('по борьбе с организованной преступностью', 66),\n",
       " ('как сообщает итар-тасс со ссылкой', 58)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = get_20_most_common(sentences1, 5)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075d7235-62df-46ec-8a2e-a0fbfa6af1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = word_tokenize(data, preserve_line=True)\n",
    "sentences2 = [token.lower() for token in sentences2 if not re.match(r'\\W+', token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4583494-e6b5-469c-a029-8448ec45706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('риа новости со ссылкой на', 400),\n",
       " ('сообщает риа новости со ссылкой', 320),\n",
       " ('как сообщили риа новости в', 196),\n",
       " ('как сообщает риа новости со', 149),\n",
       " ('сообщает интерфакс со ссылкой на', 142),\n",
       " ('сообщает итар-тасс со ссылкой на', 118),\n",
       " ('об этом риа новости сообщили', 113),\n",
       " ('об этом сообщает риа новости', 104),\n",
       " ('этом риа новости сообщили в', 99),\n",
       " ('со ссылкой на источники в', 93),\n",
       " ('сообщили риа новости в пресс-службе', 88),\n",
       " ('как сообщает интерфакс со ссылкой', 83),\n",
       " ('объединенной группировки войск на северном', 83),\n",
       " ('эхо москвы со ссылкой на', 77),\n",
       " ('новости со ссылкой на пресс-службу', 76),\n",
       " ('этом сообщает риа новости со', 75),\n",
       " ('в связи с тем что', 70),\n",
       " ('как сообщает итар-тасс со ссылкой', 58),\n",
       " ('группировки войск на северном кавказе', 57),\n",
       " ('по борьбе с организованной преступностью', 55)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = get_20_most_common([sentences2], 5)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5865a163-ba32-451d-beec-2be4cea5f1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'риа новости со ссылкой на'\t'риа новости со ссылкой на'\tнграмма совпадает\n",
      "400\t400\tколичество совпадает\n",
      "\n",
      "'сообщает риа новости со ссылкой'\t'сообщает риа новости со ссылкой'\tнграмма совпадает\n",
      "320\t320\tколичество совпадает\n",
      "\n",
      "'как сообщили риа новости в'\t'как сообщили риа новости в'\tнграмма совпадает\n",
      "196\t196\tколичество совпадает\n",
      "\n",
      "'как сообщает риа новости со'\t'как сообщает риа новости со'\tнграмма совпадает\n",
      "149\t149\tколичество совпадает\n",
      "\n",
      "'сообщает интерфакс со ссылкой на'\t'сообщает интерфакс со ссылкой на'\tнграмма совпадает\n",
      "142\t142\tколичество совпадает\n",
      "\n",
      "'сообщает итар-тасс со ссылкой на'\t'сообщает итар-тасс со ссылкой на'\tнграмма совпадает\n",
      "118\t118\tколичество совпадает\n",
      "\n",
      "'об этом риа новости сообщили'\t'об этом риа новости сообщили'\tнграмма совпадает\n",
      "113\t113\tколичество совпадает\n",
      "\n",
      "'об этом сообщает риа новости'\t'об этом сообщает риа новости'\tнграмма совпадает\n",
      "104\t104\tколичество совпадает\n",
      "\n",
      "'этом риа новости сообщили в'\t'этом риа новости сообщили в'\tнграмма совпадает\n",
      "99\t99\tколичество совпадает\n",
      "\n",
      "'со ссылкой на источники в'\t'со ссылкой на источники в'\tнграмма совпадает\n",
      "93\t93\tколичество совпадает\n",
      "\n",
      "'сообщили риа новости в пресс-службе'\t'сообщили риа новости в пресс-службе'\tнграмма совпадает\n",
      "88\t88\tколичество совпадает\n",
      "\n",
      "'группировки войск на северном кавказе'\t'как сообщает интерфакс со ссылкой'\tнграмма не совпадает\n",
      "84\t83\tколичество не совпадает\n",
      "\n",
      "'как сообщает интерфакс со ссылкой'\t'объединенной группировки войск на северном'\tнграмма не совпадает\n",
      "83\t83\tколичество совпадает\n",
      "\n",
      "'объединенной группировки войск на северном'\t'эхо москвы со ссылкой на'\tнграмма не совпадает\n",
      "83\t77\tколичество не совпадает\n",
      "\n",
      "'новости со ссылкой на пресс-службу'\t'новости со ссылкой на пресс-службу'\tнграмма совпадает\n",
      "76\t76\tколичество совпадает\n",
      "\n",
      "'эхо москвы со ссылкой на'\t'этом сообщает риа новости со'\tнграмма не совпадает\n",
      "76\t75\tколичество не совпадает\n",
      "\n",
      "'этом сообщает риа новости со'\t'в связи с тем что'\tнграмма не совпадает\n",
      "75\t70\tколичество не совпадает\n",
      "\n",
      "'в связи с тем что'\t'как сообщает итар-тасс со ссылкой'\tнграмма не совпадает\n",
      "70\t58\tколичество не совпадает\n",
      "\n",
      "'по борьбе с организованной преступностью'\t'группировки войск на северном кавказе'\tнграмма не совпадает\n",
      "66\t57\tколичество не совпадает\n",
      "\n",
      "'как сообщает итар-тасс со ссылкой'\t'по борьбе с организованной преступностью'\tнграмма не совпадает\n",
      "58\t55\tколичество не совпадает\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngramm_verdict = (\"нграмма не совпадает\", \"нграмма совпадает\")\n",
    "count_verdict  = (\"количество не совпадает\", \"количество совпадает\")\n",
    "\n",
    "for elem1, elem2 in zip(result1, result2):\n",
    "    ngramm1, count1 = elem1\n",
    "    ngramm2, count2 = elem2\n",
    "\n",
    "    print(repr(ngramm1), repr(ngramm2), ngramm_verdict[ngramm1 == ngramm2], sep=\"\\t\")\n",
    "    print(count1, count2, count_verdict[count1 == count2], sep=\"\\t\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583abd1-d046-49a9-9472-3d0826b873ae",
   "metadata": {},
   "source": [
    "<h1>Результат</h1>\n",
    "По большей части пайплайны обработки работают одинаково, однако второй вариант (word_tokenize напрямую) иногда теряет часть валидных совпадений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5781f34",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292716e",
   "metadata": {},
   "source": [
    "Найдите какую-то инетересную (по вашему мнению) закономерность на https://books.google.com/ngrams/ для русского языка (с 1990 по 2022)\n",
    "\n",
    "Вставьте сюда скриншот"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4a51a-cece-4851-9b81-335f55f0a317",
   "metadata": {},
   "source": [
    "<img src=\"data/1.png\" align=\"center\">\n",
    "<img src=\"data/2.png\" align=\"center\"> \n",
    "<img src=\"data/3.png\" align=\"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a89ec",
   "metadata": {},
   "source": [
    "## Заданиe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c35e9",
   "metadata": {},
   "source": [
    "Когда мы разбирали PMI мы использовали такую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221f1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_simple(word_count_a, word_count_b, bigram_count, *args):\n",
    "    try:\n",
    "        score = bigram_count/((word_count_a+word_count_b))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd2def",
   "metadata": {},
   "source": [
    "Но если вы посмотрите на определение в википедии, то увидите, что формула немного другая ![](https://wikimedia.org/api/rest_v1/media/math/render/svg/094243d23c19d2d032f6bb26c4dc4f47d98d32f8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1905862",
   "metadata": {},
   "source": [
    "Перепишите функцию, чтобы она точно соответствовала этому определению. Расчитайте PMI для всех биграммов также как мы делали в семинаре с помощью функции score_bigrams используя изначальный scorer и обновленный. Посмотрите есть ли разница в топ-10 биграммов. Подумайте почему результаты совпадают/отличаются?\n",
    "\n",
    "*Подсказка: для вероятностей можно поделить на количество слов в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1431f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Подгрузка сущностей с семинара\n",
    "\n",
    "sentences = sent_tokenize(data, language='russian')\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "tokenized_sentences = [[token.lower() for token in sentence if not re.match(r'\\W+', token)] \n",
    "                       for sentence in tokenized_sentences]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "token_counts = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    token_counts.update([token for token in sentence if token not in russian_stopwords])\n",
    "\n",
    "bigram_counts = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    bigram_counts.update(ngrammer([token for token in sentence if token not in russian_stopwords]))\n",
    "\n",
    "def ngrammer(tokens, n=2, stops=set()):\n",
    "    ngrams = []\n",
    "    tokens = [token for token in tokens if token not in stops]\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def collect_stats(corpus, stops):\n",
    "    ## соберем статистики для отдельных слов\n",
    "    ## и биграммов\n",
    "    \n",
    "    unigrams = Counter()\n",
    "    bigrams = Counter()\n",
    "    \n",
    "    for sent in corpus:\n",
    "        unigrams.update(sent)\n",
    "        bigrams.update(ngrammer(sent, 2, stops))\n",
    "    \n",
    "    return unigrams, bigrams\n",
    "\n",
    "\n",
    "def score_bigrams(unigrams, bigrams, scorer, threshold=-100000):\n",
    "    ## посчитаем метрику для каждого нграмма\n",
    "    bigram2score = Counter()\n",
    "    \n",
    "    for bigram in bigrams:\n",
    "        word_a, word_b = bigram.split()\n",
    "        score = scorer(unigrams[word_a], unigrams[word_b], \n",
    "                       bigrams[bigram])\n",
    "        \n",
    "        ## если метрика выше порога, добавляем в словарик\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    \n",
    "    return bigram2score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdaf8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams = collect_stats(tokenized_sentences, russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d413c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сопоцкина друскеник', 0.5),\n",
       " ('неприятель приблизившись', 0.5),\n",
       " ('саноку обстреливалась', 0.5),\n",
       " ('м.ю лермонтова', 0.5),\n",
       " ('австрийский аэроплан', 0.5),\n",
       " ('показывался аэроплан-птица', 0.5),\n",
       " ('das ist', 0.5),\n",
       " ('ist nesteroff', 0.5),\n",
       " ('песнь нестерове', 0.5),\n",
       " ('могучий унесся', 0.5),\n",
       " ('шумели лязгали', 0.5),\n",
       " ('зловеще гремели.и', 0.5),\n",
       " ('гремели.и пламенно', 0.5),\n",
       " ('жаждали битвы…величие', 0.5),\n",
       " ('равнине обманчиво-зыбкой.презрение', 0.5)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  результат работы скорера с семинара\n",
    "\n",
    "bigram2score = score_bigrams(unigrams, bigrams, scorer_simple)\n",
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee3b66ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('риа новости', 0.4900746163592848),\n",
       " ('северном кавказе', 0.44553483807654565),\n",
       " ('associated press', 0.4345991561181435),\n",
       " ('new york', 0.4218009478672986),\n",
       " ('сих пор', 0.39092055485498106),\n",
       " ('взрывное устройство', 0.3665768194070081),\n",
       " ('таким образом', 0.3657187993680885),\n",
       " ('рао еэс', 0.33954451345755693),\n",
       " ('доменных имен', 0.31512605042016806),\n",
       " ('чрезвычайным ситуациям', 0.30935251798561153),\n",
       " ('налогам сборам', 0.30201342281879195),\n",
       " ('wall street', 0.3018867924528302),\n",
       " ('населенного пункта', 0.3013698630136986),\n",
       " ('объединенной группировки', 0.2993421052631579),\n",
       " ('возбуждено уголовное', 0.2983606557377049)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  результат работы скорера+эвристики с семинара\n",
    "\n",
    "\n",
    "def scorer(word_count_a, word_count_b, bigram_count, min_count=0):\n",
    "    try:\n",
    "        score = ((bigram_count - min_count) / ((word_count_a + word_count_b)))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "    return score\n",
    "\n",
    "# добавим параметр min_count\n",
    "def score_bigrams(unigrams, bigrams, scorer, threshold=-100000, min_count=0):\n",
    "    ## посчитаем метрику для каждого нграмма\n",
    "    bigram2score = Counter()\n",
    "    \n",
    "    for bigram in bigrams:\n",
    "        word_a, word_b = bigram.split()\n",
    "        score = scorer(unigrams[word_a], unigrams[word_b], bigrams[bigram], min_count)\n",
    "        \n",
    "        ## если метрика выше порога, добавляем в словарик\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    \n",
    "    return bigram2score\n",
    "\n",
    "bigram2score = score_bigrams(unigrams, bigrams, scorer, min_count=20)\n",
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4a77b",
   "metadata": {},
   "source": [
    "**РЕШЕНИЕ ЗАДАЧИ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bea4905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_11808\\1841684675.py:15: RuntimeWarning: invalid value encountered in log2\n",
      "  score = np.log2(score)\n",
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_11808\\1841684675.py:15: RuntimeWarning: divide by zero encountered in log2\n",
      "  score = np.log2(score)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wall street', np.float64(14.560801346515762)),\n",
       " ('саудовской аравии', np.float64(14.548952071027742)),\n",
       " ('street journal', np.float64(14.37671828207679)),\n",
       " ('dow jones', np.float64(14.350792649635146)),\n",
       " ('подписных листов', np.float64(14.30417486066219)),\n",
       " ('следственном изоляторе', np.float64(14.281062505569599)),\n",
       " ('чрезвычайным ситуациям', np.float64(14.2051833607674)),\n",
       " ('france presse', np.float64(14.186053568262635)),\n",
       " ('персидском заливе', np.float64(14.180321069273287)),\n",
       " ('полевые командиры', np.float64(14.179627299103203)),\n",
       " ('полевых командиров', np.float64(14.080668819015033)),\n",
       " ('налогам сборам', np.float64(14.077529111484466)),\n",
       " ('следственный изолятор', np.float64(14.016128566820322)),\n",
       " ('великой отечественной', np.float64(14.005180930555012)),\n",
       " ('exit polls', np.float64(13.993760753791868))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Solution:\n",
    "\n",
    "    @staticmethod\n",
    "    def scorer(word_a_proba, word_b_proba, bigram_proba, min_count=0, *args):\n",
    "\n",
    "        #  P(a|b) = P(a * b) / P(b)\n",
    "\n",
    "        conditional_proba = (bigram_proba - min_count) / word_b_proba\n",
    "\n",
    "        try:\n",
    "            #  P(a|b) / P(a)\n",
    "            score = conditional_proba / word_a_proba\n",
    "            score = np.log2(score)\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def score_bigrams(unigrams, bigrams, scorer, threshold=-100000, min_count=0):\n",
    "        ## посчитаем метрику для каждого нграмма\n",
    "        bigram2score = Counter()\n",
    "        uni_corpus_capacity = unigrams.total()\n",
    "        bi_corpus_capacity  = bigrams .total()\n",
    "        \n",
    "        for bigram in bigrams:\n",
    "            word_a, word_b = bigram.split()\n",
    "\n",
    "            score = scorer(\n",
    "                unigrams[word_a] / uni_corpus_capacity,\n",
    "                unigrams[word_b] / uni_corpus_capacity,\n",
    "                (bigrams[bigram] )  / bi_corpus_capacity,\n",
    "                min_count\n",
    "            )\n",
    "            \n",
    "            ## если метрика выше порога, добавляем в словарик\n",
    "            if score > threshold:\n",
    "                bigram2score[bigram] = score\n",
    "        \n",
    "        return bigram2score\n",
    "    \n",
    "bigram2score = Solution.score_bigrams(unigrams, bigrams, Solution.scorer, min_count=20)\n",
    "bigram2score.most_common(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbf807",
   "metadata": {},
   "source": [
    "## Задание 4*\n",
    "\n",
    "Обновите функцию получившуюся в предыдущем задании так, чтобы вместо произведения/деления вероятностей использовались сложение и вычитание логирифмов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "083bdf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_11808\\4184021003.py:9: RuntimeWarning: invalid value encountered in log\n",
      "  conditional_proba = np.log(bigram_proba - min_count) - np.log(word_b_proba)\n",
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_11808\\4184021003.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  conditional_proba = np.log(bigram_proba - min_count) - np.log(word_b_proba)\n",
      "C:\\Users\\Kirill\\AppData\\Local\\Temp\\ipykernel_11808\\4184021003.py:14: RuntimeWarning: divide by zero encountered in log2\n",
      "  score = np.log2(np.exp(score))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wall street', np.float64(14.560801346515765)),\n",
       " ('саудовской аравии', np.float64(14.54895207102774)),\n",
       " ('street journal', np.float64(14.37671828207679)),\n",
       " ('dow jones', np.float64(14.350792649635148)),\n",
       " ('подписных листов', np.float64(14.30417486066219)),\n",
       " ('следственном изоляторе', np.float64(14.281062505569599)),\n",
       " ('чрезвычайным ситуациям', np.float64(14.205183360767396)),\n",
       " ('france presse', np.float64(14.186053568262636)),\n",
       " ('персидском заливе', np.float64(14.180321069273289)),\n",
       " ('полевые командиры', np.float64(14.179627299103203)),\n",
       " ('полевых командиров', np.float64(14.080668819015031)),\n",
       " ('налогам сборам', np.float64(14.077529111484466)),\n",
       " ('следственный изолятор', np.float64(14.016128566820326)),\n",
       " ('великой отечественной', np.float64(14.005180930555012)),\n",
       " ('exit polls', np.float64(13.993760753791868))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Solution:\n",
    "\n",
    "    @staticmethod\n",
    "    def scorer(word_a_proba, word_b_proba, bigram_proba, min_count=0, *args):\n",
    "\n",
    "        #  P(a|b) = P(a * b) / P(b)\n",
    "        conditional_proba = np.log(bigram_proba - min_count) - np.log(word_b_proba)\n",
    "\n",
    "        try:\n",
    "            #  P(a|b) / P(a)\n",
    "            score = conditional_proba - np.log(word_a_proba)\n",
    "            score = np.log2(np.exp(score))\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def score_bigrams(unigrams, bigrams, scorer, threshold=-100000, min_count=0):\n",
    "        ## посчитаем метрику для каждого нграмма\n",
    "        bigram2score = Counter()\n",
    "        uni_corpus_capacity = unigrams.total()\n",
    "        bi_corpus_capacity  = bigrams .total()\n",
    "        \n",
    "        for bigram in bigrams:\n",
    "            word_a, word_b = bigram.split()\n",
    "\n",
    "            score = scorer(\n",
    "                unigrams[word_a] / uni_corpus_capacity,\n",
    "                unigrams[word_b] / uni_corpus_capacity,\n",
    "                (bigrams[bigram] - min_count)  / bi_corpus_capacity,\n",
    "            )\n",
    "            \n",
    "            ## если метрика выше порога, добавляем в словарик\n",
    "            if score > threshold:\n",
    "                bigram2score[bigram] = score\n",
    "        \n",
    "        return bigram2score\n",
    "    \n",
    "bigram2score = Solution.score_bigrams(unigrams, bigrams, Solution.scorer, min_count=20)\n",
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22785f4",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1121e53",
   "metadata": {},
   "source": [
    "Исследуйте gensim.models.Phrases. Проверьте сколько дефолтных scoring функций есть в этом классе. Попробуйте все доступные по умолчанию scoring функции и попробуйте настраивать для них значение threshold и min_count. Попробуйте сделать так, чтобы собиралось как можно больше нграммов. Попробуйте строить последовательность gensim.models.Phrases, чтобы строить более длинные нграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716fba84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
