{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите 1 любой способ сломать токенизацию на предложения функцией sentenize из библиотеки razdel. Придумайте (или найдите на каком-то корпусе) такое предложение (или несколько предложений), которое будет некорректно разобрано sentenize, но при этом будет грамматически корректным. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комментарий \n",
    "Тут получилось поймать целых 2 косяка:\n",
    "- `\"Пятьдесят шесть. О мухах\"` -- это единый компонент\n",
    "- `\"В 2009 году вышел роман \"t\", написанный Пелевиным В. А.\"` и `\"\"S.N.U.F.F.\" же, явившийся свету тремя годами позже, до сих пор радует нас шедевральным отрывком \"Пятьдесят шесть. О мухах\".\"` -- это разные предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring(0, 170, 'В 2009 году вышел роман \"t\", написанный Пелевиным В. А.\\n\"S.N.U.F.F.\" же, явившийся свету тремя годами позже, до сих пор радует нас шедевральным отрывком \"Пятьдесят шесть.')\n",
      "Substring(171, 180, 'О мухах\".')\n"
     ]
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "\n",
    "\n",
    "doc = \"\"\"\n",
    "В 2009 году вышел роман \"t\", написанный Пелевиным В. А.\n",
    "\"S.N.U.F.F.\" же, явившийся свету тремя годами позже, до сих пор радует нас шедевральным отрывком \"Пятьдесят шесть. О мухах\".\n",
    "\"\"\".strip() \n",
    "\n",
    "for sentence in sentenize(doc):\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Токенизация Mystem vs razdel.tokenize (2 балла)\n",
    "\n",
    "\n",
    "Токенизируйте текст с помощью razdel и с помощью Mystem. Найдите различия в токенизациях. Что по вашему работает лучше на приведенном тексте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Вторым и третьим открытыми белыми карликами стали Сириус B и Процион B. В 1844 году директор Кёнигсбергской обсерватории Фридрих Бессель, анализируя данные наблюдений, которые велись с 1755 года, обнаружил, что Сириус, ярчайшая звезда земного неба, и Процион периодически, хотя и весьма слабо, отклоняются от прямолинейной траектории движения по небесной сфере[5]. Бессель пришёл к выводу, что у каждой из них должен быть близкий спутник. Сообщение было встречено скептически, поскольку слабый спутник оставался ненаблюдаемым, а его масса должна была быть достаточно велика — сравнимой с массой Сириуса и Проциона, соответственно.\n",
    "\n",
    "В январе 1862 года Элвин Грэхэм Кларк, юстируя 18-дюймовый рефрактор, самый большой на то время телескоп в мире (Dearborn Telescope), впоследствии поставленный семейной фирмой Кларков в обсерваторию Чикагского университета, обнаружил в непосредственной близости от Сириуса тусклую звёздочку. Это был спутник Сириуса, Сириус B, предсказанный Бесселем[6]. А в 1896 году американский астроном Д. М. Шеберле открыл Процион B, подтвердив тем самым и второе предсказание Бесселя.\n",
    "\n",
    "В 1915 году американский астроном Уолтер Сидней Адамс измерил спектр Сириуса B. Из измерений следовало, что его температура не ниже, чем у Сириуса A (по современным данным, температура поверхности Сириуса B составляет 25 000 K, а Сириуса A — 10 000 К), что, с учётом его в 10 000 раз меньшей, чем у Сириуса A, светимости указывает на очень малый радиус и, соответственно, высокую плотность — 106 г/см3 (плотность Сириуса ~0,25 г/см3, плотность Солнца ~1,4 г/см3).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring(1, 7, 'Вторым')\n",
      "Substring(8, 9, 'и')\n",
      "Substring(10, 17, 'третьим')\n",
      "Substring(18, 27, 'открытыми')\n",
      "Substring(28, 34, 'белыми')\n",
      "Substring(35, 44, 'карликами')\n",
      "Substring(45, 50, 'стали')\n",
      "Substring(51, 57, 'Сириус')\n",
      "Substring(58, 59, 'B')\n",
      "Substring(60, 61, 'и')\n",
      "Substring(62, 69, 'Процион')\n",
      "Substring(70, 71, 'B')\n",
      "Substring(71, 72, '.')\n",
      "Substring(73, 74, 'В')\n",
      "Substring(75, 79, '1844')\n",
      "Substring(80, 84, 'году')\n",
      "Substring(85, 93, 'директор')\n",
      "Substring(94, 108, 'Кёнигсбергской')\n",
      "Substring(109, 121, 'обсерватории')\n",
      "Substring(122, 129, 'Фридрих')\n",
      "Substring(130, 137, 'Бессель')\n",
      "Substring(137, 138, ',')\n",
      "Substring(139, 149, 'анализируя')\n",
      "Substring(150, 156, 'данные')\n",
      "Substring(157, 167, 'наблюдений')\n",
      "Substring(167, 168, ',')\n",
      "Substring(169, 176, 'которые')\n",
      "Substring(177, 183, 'велись')\n",
      "Substring(184, 185, 'с')\n",
      "Substring(186, 190, '1755')\n",
      "Substring(191, 195, 'года')\n",
      "Substring(195, 196, ',')\n",
      "Substring(197, 206, 'обнаружил')\n",
      "Substring(206, 207, ',')\n",
      "Substring(208, 211, 'что')\n",
      "Substring(212, 218, 'Сириус')\n",
      "Substring(218, 219, ',')\n",
      "Substring(220, 228, 'ярчайшая')\n",
      "Substring(229, 235, 'звезда')\n",
      "Substring(236, 243, 'земного')\n",
      "Substring(244, 248, 'неба')\n",
      "Substring(248, 249, ',')\n",
      "Substring(250, 251, 'и')\n",
      "Substring(252, 259, 'Процион')\n",
      "Substring(260, 272, 'периодически')\n",
      "Substring(272, 273, ',')\n",
      "Substring(274, 278, 'хотя')\n",
      "Substring(279, 280, 'и')\n",
      "Substring(281, 287, 'весьма')\n",
      "Substring(288, 293, 'слабо')\n",
      "Substring(293, 294, ',')\n",
      "Substring(295, 306, 'отклоняются')\n",
      "Substring(307, 309, 'от')\n",
      "Substring(310, 323, 'прямолинейной')\n",
      "Substring(324, 334, 'траектории')\n",
      "Substring(335, 343, 'движения')\n",
      "Substring(344, 346, 'по')\n",
      "Substring(347, 355, 'небесной')\n",
      "Substring(356, 361, 'сфере')\n",
      "Substring(361, 362, '[')\n",
      "Substring(362, 363, '5')\n",
      "Substring(363, 364, ']')\n",
      "Substring(364, 365, '.')\n",
      "Substring(366, 373, 'Бессель')\n",
      "Substring(374, 380, 'пришёл')\n",
      "Substring(381, 382, 'к')\n",
      "Substring(383, 389, 'выводу')\n",
      "Substring(389, 390, ',')\n",
      "Substring(391, 394, 'что')\n",
      "Substring(395, 396, 'у')\n",
      "Substring(397, 403, 'каждой')\n",
      "Substring(404, 406, 'из')\n",
      "Substring(407, 410, 'них')\n",
      "Substring(411, 417, 'должен')\n",
      "Substring(418, 422, 'быть')\n",
      "Substring(423, 430, 'близкий')\n",
      "Substring(431, 438, 'спутник')\n",
      "Substring(438, 439, '.')\n",
      "Substring(440, 449, 'Сообщение')\n",
      "Substring(450, 454, 'было')\n",
      "Substring(455, 464, 'встречено')\n",
      "Substring(465, 476, 'скептически')\n",
      "Substring(476, 477, ',')\n",
      "Substring(478, 487, 'поскольку')\n",
      "Substring(488, 494, 'слабый')\n",
      "Substring(495, 502, 'спутник')\n",
      "Substring(503, 512, 'оставался')\n",
      "Substring(513, 526, 'ненаблюдаемым')\n",
      "Substring(526, 527, ',')\n",
      "Substring(528, 529, 'а')\n",
      "Substring(530, 533, 'его')\n",
      "Substring(534, 539, 'масса')\n",
      "Substring(540, 546, 'должна')\n",
      "Substring(547, 551, 'была')\n",
      "Substring(552, 556, 'быть')\n",
      "Substring(557, 567, 'достаточно')\n",
      "Substring(568, 574, 'велика')\n",
      "Substring(575, 576, '—')\n",
      "Substring(577, 586, 'сравнимой')\n",
      "Substring(587, 588, 'с')\n",
      "Substring(589, 595, 'массой')\n",
      "Substring(596, 603, 'Сириуса')\n",
      "Substring(604, 605, 'и')\n",
      "Substring(606, 614, 'Проциона')\n",
      "Substring(614, 615, ',')\n",
      "Substring(616, 630, 'соответственно')\n",
      "Substring(630, 631, '.')\n",
      "Substring(633, 634, 'В')\n",
      "Substring(635, 641, 'январе')\n",
      "Substring(642, 646, '1862')\n",
      "Substring(647, 651, 'года')\n",
      "Substring(652, 657, 'Элвин')\n",
      "Substring(658, 664, 'Грэхэм')\n",
      "Substring(665, 670, 'Кларк')\n",
      "Substring(670, 671, ',')\n",
      "Substring(672, 679, 'юстируя')\n",
      "Substring(680, 691, '18-дюймовый')\n",
      "Substring(692, 701, 'рефрактор')\n",
      "Substring(701, 702, ',')\n",
      "Substring(703, 708, 'самый')\n",
      "Substring(709, 716, 'большой')\n",
      "Substring(717, 719, 'на')\n",
      "Substring(720, 722, 'то')\n",
      "Substring(723, 728, 'время')\n",
      "Substring(729, 737, 'телескоп')\n",
      "Substring(738, 739, 'в')\n",
      "Substring(740, 744, 'мире')\n",
      "Substring(745, 746, '(')\n",
      "Substring(746, 754, 'Dearborn')\n",
      "Substring(755, 764, 'Telescope')\n",
      "Substring(764, 765, ')')\n",
      "Substring(765, 766, ',')\n",
      "Substring(767, 779, 'впоследствии')\n",
      "Substring(780, 792, 'поставленный')\n",
      "Substring(793, 801, 'семейной')\n",
      "Substring(802, 808, 'фирмой')\n",
      "Substring(809, 816, 'Кларков')\n",
      "Substring(817, 818, 'в')\n",
      "Substring(819, 831, 'обсерваторию')\n",
      "Substring(832, 842, 'Чикагского')\n",
      "Substring(843, 855, 'университета')\n",
      "Substring(855, 856, ',')\n",
      "Substring(857, 866, 'обнаружил')\n",
      "Substring(867, 868, 'в')\n",
      "Substring(869, 885, 'непосредственной')\n",
      "Substring(886, 894, 'близости')\n",
      "Substring(895, 897, 'от')\n",
      "Substring(898, 905, 'Сириуса')\n",
      "Substring(906, 913, 'тусклую')\n",
      "Substring(914, 923, 'звёздочку')\n",
      "Substring(923, 924, '.')\n",
      "Substring(925, 928, 'Это')\n",
      "Substring(929, 932, 'был')\n",
      "Substring(933, 940, 'спутник')\n",
      "Substring(941, 948, 'Сириуса')\n",
      "Substring(948, 949, ',')\n",
      "Substring(950, 956, 'Сириус')\n",
      "Substring(957, 958, 'B')\n",
      "Substring(958, 959, ',')\n",
      "Substring(960, 973, 'предсказанный')\n",
      "Substring(974, 982, 'Бесселем')\n",
      "Substring(982, 983, '[')\n",
      "Substring(983, 984, '6')\n",
      "Substring(984, 985, ']')\n",
      "Substring(985, 986, '.')\n",
      "Substring(987, 988, 'А')\n",
      "Substring(989, 990, 'в')\n",
      "Substring(991, 995, '1896')\n",
      "Substring(996, 1000, 'году')\n",
      "Substring(1001, 1013, 'американский')\n",
      "Substring(1014, 1022, 'астроном')\n",
      "Substring(1023, 1024, 'Д')\n",
      "Substring(1024, 1025, '.')\n",
      "Substring(1026, 1027, 'М')\n",
      "Substring(1027, 1028, '.')\n",
      "Substring(1029, 1036, 'Шеберле')\n",
      "Substring(1037, 1043, 'открыл')\n",
      "Substring(1044, 1051, 'Процион')\n",
      "Substring(1052, 1053, 'B')\n",
      "Substring(1053, 1054, ',')\n",
      "Substring(1055, 1065, 'подтвердив')\n",
      "Substring(1066, 1069, 'тем')\n",
      "Substring(1070, 1075, 'самым')\n",
      "Substring(1076, 1077, 'и')\n",
      "Substring(1078, 1084, 'второе')\n",
      "Substring(1085, 1097, 'предсказание')\n",
      "Substring(1098, 1105, 'Бесселя')\n",
      "Substring(1105, 1106, '.')\n",
      "Substring(1108, 1109, 'В')\n",
      "Substring(1110, 1114, '1915')\n",
      "Substring(1115, 1119, 'году')\n",
      "Substring(1120, 1132, 'американский')\n",
      "Substring(1133, 1141, 'астроном')\n",
      "Substring(1142, 1148, 'Уолтер')\n",
      "Substring(1149, 1155, 'Сидней')\n",
      "Substring(1156, 1161, 'Адамс')\n",
      "Substring(1162, 1169, 'измерил')\n",
      "Substring(1170, 1176, 'спектр')\n",
      "Substring(1177, 1184, 'Сириуса')\n",
      "Substring(1185, 1186, 'B')\n",
      "Substring(1186, 1187, '.')\n",
      "Substring(1188, 1190, 'Из')\n",
      "Substring(1191, 1200, 'измерений')\n",
      "Substring(1201, 1210, 'следовало')\n",
      "Substring(1210, 1211, ',')\n",
      "Substring(1212, 1215, 'что')\n",
      "Substring(1216, 1219, 'его')\n",
      "Substring(1220, 1231, 'температура')\n",
      "Substring(1232, 1234, 'не')\n",
      "Substring(1235, 1239, 'ниже')\n",
      "Substring(1239, 1240, ',')\n",
      "Substring(1241, 1244, 'чем')\n",
      "Substring(1245, 1246, 'у')\n",
      "Substring(1247, 1254, 'Сириуса')\n",
      "Substring(1255, 1256, 'A')\n",
      "Substring(1257, 1258, '(')\n",
      "Substring(1258, 1260, 'по')\n",
      "Substring(1261, 1272, 'современным')\n",
      "Substring(1273, 1279, 'данным')\n",
      "Substring(1279, 1280, ',')\n",
      "Substring(1281, 1292, 'температура')\n",
      "Substring(1293, 1304, 'поверхности')\n",
      "Substring(1305, 1312, 'Сириуса')\n",
      "Substring(1313, 1314, 'B')\n",
      "Substring(1315, 1325, 'составляет')\n",
      "Substring(1326, 1328, '25')\n",
      "Substring(1329, 1332, '000')\n",
      "Substring(1333, 1334, 'K')\n",
      "Substring(1334, 1335, ',')\n",
      "Substring(1336, 1337, 'а')\n",
      "Substring(1338, 1345, 'Сириуса')\n",
      "Substring(1346, 1347, 'A')\n",
      "Substring(1348, 1349, '—')\n",
      "Substring(1350, 1352, '10')\n",
      "Substring(1353, 1356, '000')\n",
      "Substring(1357, 1358, 'К')\n",
      "Substring(1358, 1359, ')')\n",
      "Substring(1359, 1360, ',')\n",
      "Substring(1361, 1364, 'что')\n",
      "Substring(1364, 1365, ',')\n",
      "Substring(1366, 1367, 'с')\n",
      "Substring(1368, 1374, 'учётом')\n",
      "Substring(1375, 1378, 'его')\n",
      "Substring(1379, 1380, 'в')\n",
      "Substring(1381, 1383, '10')\n",
      "Substring(1384, 1387, '000')\n",
      "Substring(1388, 1391, 'раз')\n",
      "Substring(1392, 1399, 'меньшей')\n",
      "Substring(1399, 1400, ',')\n",
      "Substring(1401, 1404, 'чем')\n",
      "Substring(1405, 1406, 'у')\n",
      "Substring(1407, 1414, 'Сириуса')\n",
      "Substring(1415, 1416, 'A')\n",
      "Substring(1416, 1417, ',')\n",
      "Substring(1418, 1428, 'светимости')\n",
      "Substring(1429, 1438, 'указывает')\n",
      "Substring(1439, 1441, 'на')\n",
      "Substring(1442, 1447, 'очень')\n",
      "Substring(1448, 1453, 'малый')\n",
      "Substring(1454, 1460, 'радиус')\n",
      "Substring(1461, 1462, 'и')\n",
      "Substring(1462, 1463, ',')\n",
      "Substring(1464, 1478, 'соответственно')\n",
      "Substring(1478, 1479, ',')\n",
      "Substring(1480, 1487, 'высокую')\n",
      "Substring(1488, 1497, 'плотность')\n",
      "Substring(1498, 1499, '—')\n",
      "Substring(1500, 1503, '106')\n",
      "Substring(1504, 1505, 'г')\n",
      "Substring(1505, 1506, '/')\n",
      "Substring(1506, 1508, 'см')\n",
      "Substring(1508, 1509, '3')\n",
      "Substring(1510, 1511, '(')\n",
      "Substring(1511, 1520, 'плотность')\n",
      "Substring(1521, 1528, 'Сириуса')\n",
      "Substring(1529, 1530, '~')\n",
      "Substring(1530, 1534, '0,25')\n",
      "Substring(1535, 1536, 'г')\n",
      "Substring(1536, 1537, '/')\n",
      "Substring(1537, 1539, 'см')\n",
      "Substring(1539, 1540, '3')\n",
      "Substring(1540, 1541, ',')\n",
      "Substring(1542, 1551, 'плотность')\n",
      "Substring(1552, 1558, 'Солнца')\n",
      "Substring(1559, 1560, '~')\n",
      "Substring(1560, 1563, '1,4')\n",
      "Substring(1564, 1565, 'г')\n",
      "Substring(1565, 1566, '/')\n",
      "Substring(1566, 1568, 'см')\n",
      "Substring(1568, 1569, '3')\n",
      "Substring(1569, 1570, ')')\n",
      "Substring(1570, 1571, '.')\n"
     ]
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "for token in tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '\\n'}\n",
      "{'analysis': [{'lex': 'второй', 'wt': 0.986135184, 'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'}], 'text': 'Вторым'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'третий', 'wt': 0.9944396734, 'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'}], 'text': 'третьим'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'открытый', 'wt': 0.959315763, 'gr': 'A=твор,мн,полн'}], 'text': 'открытыми'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'белый', 'wt': 0.9932845421, 'gr': 'A=твор,мн,полн'}], 'text': 'белыми'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'карлик', 'wt': 1, 'gr': 'S,муж,од=твор,мн'}], 'text': 'карликами'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'становиться', 'wt': 0.9821285244, 'gr': 'V,нп=прош,мн,изъяв,сов'}], 'text': 'стали'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}], 'text': 'Сириус'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'процион', 'wt': 1, 'qual': 'bastard', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'Процион'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'В'}\n",
      "{'text': ' '}\n",
      "{'text': '1844'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'год', 'wt': 1, 'gr': 'S,муж,неод=(дат,ед|местн,ед)'}], 'text': 'году'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'директор', 'wt': 1, 'gr': 'S,муж,од=им,ед'}], 'text': 'директор'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'кенигсбергский', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'Кёнигсбергской'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'обсерватория', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'обсерватории'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'фридрих', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Фридрих'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'бессель', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Бессель'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'анализировать', 'wt': 1, 'gr': 'V,несов,пе=непрош,деепр'}], 'text': 'анализируя'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'данные', 'wt': 0.8760081205, 'gr': 'S,мн,неод=(вин|им)'}], 'text': 'данные'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'наблюдение', 'wt': 1, 'gr': 'S,сред,неод=род,мн'}], 'text': 'наблюдений'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'который', 'wt': 1, 'gr': 'APRO=(им,мн|вин,мн,неод)'}], 'text': 'которые'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'вестись', 'wt': 0.5361965901, 'gr': 'V,несов,нп=прош,мн,изъяв'}], 'text': 'велись'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'с', 'wt': 0.999977831, 'gr': 'PR='}], 'text': 'с'}\n",
      "{'text': ' '}\n",
      "{'text': '1755'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'год', 'wt': 1, 'gr': 'S,муж,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'года'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'обнаруживать', 'wt': 1, 'gr': 'V,пе=прош,ед,изъяв,муж,сов'}], 'text': 'обнаружил'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'что', 'wt': 0.688532576, 'gr': 'CONJ='}], 'text': 'что'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}], 'text': 'Сириус'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'яркий', 'wt': 1, 'gr': 'A=им,ед,полн,прев,жен'}], 'text': 'ярчайшая'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'звезда', 'wt': 0.690962732, 'gr': 'S,жен,неод=им,ед'}], 'text': 'звезда'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'земной', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,од|род,ед,полн,муж|род,ед,полн,сред)'}], 'text': 'земного'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'небо', 'wt': 0.5986169838, 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'неба'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'процион', 'wt': 1, 'qual': 'bastard', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'Процион'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'периодически', 'wt': 0.9999489765, 'gr': 'ADV='}], 'text': 'периодически'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'хотя', 'wt': 0.7674314765, 'gr': 'CONJ='}], 'text': 'хотя'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'весьма', 'wt': 1, 'gr': 'ADV='}], 'text': 'весьма'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'слабо', 'wt': 0.9235434159, 'gr': 'ADV='}], 'text': 'слабо'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'отклоняться', 'wt': 1, 'gr': 'V,нп=непрош,мн,изъяв,3-л,несов'}], 'text': 'отклоняются'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'от', 'wt': 1, 'gr': 'PR='}], 'text': 'от'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'прямолинейный', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'прямолинейной'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'траектория', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'траектории'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'движение', 'wt': 1, 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'движения'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'по', 'wt': 1, 'gr': 'PR='}], 'text': 'по'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'небесный', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'небесной'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сфера', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|дат,ед)'}], 'text': 'сфере'}\n",
      "{'text': '['}\n",
      "{'text': '5'}\n",
      "{'text': ']'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'бессель', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Бессель'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'приходить', 'wt': 0.9984379383, 'gr': 'V,нп=прош,ед,изъяв,муж,сов'}], 'text': 'пришёл'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'к', 'wt': 0.9999551798, 'gr': 'PR='}], 'text': 'к'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'вывод', 'wt': 1, 'gr': 'S,муж,неод=дат,ед'}], 'text': 'выводу'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'что', 'wt': 0.688532576, 'gr': 'CONJ='}], 'text': 'что'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'у', 'wt': 0.9993940324, 'gr': 'PR='}], 'text': 'у'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'каждый', 'wt': 0.9971198475, 'gr': 'APRO=(пр,ед,жен|дат,ед,жен|род,ед,жен|твор,ед,жен)'}], 'text': 'каждой'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'из', 'wt': 0.9999999775, 'gr': 'PR='}], 'text': 'из'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'они', 'wt': 1, 'gr': 'SPRO,мн=(пр|вин|род)'}], 'text': 'них'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'должный', 'wt': 1, 'gr': 'A=ед,кр,муж'}], 'text': 'должен'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'быть', 'wt': 1, 'gr': 'V,нп=инф,несов'}], 'text': 'быть'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'близкий', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'близкий'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'спутник', 'wt': 1, 'gr': 'S,муж=(им,ед,од|вин,ед,неод|им,ед,неод)'}], 'text': 'спутник'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'сообщение', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'Сообщение'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'быть', 'wt': 0.975680698, 'gr': 'V,нп=прош,ед,изъяв,сред,несов'}], 'text': 'было'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'встречать', 'wt': 1, 'gr': 'V,пе=прош,ед,прич,кр,сред,сов,страд'}], 'text': 'встречено'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'скептически', 'wt': 0.9999643443, 'gr': 'ADV='}], 'text': 'скептически'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'поскольку', 'wt': 1, 'gr': 'CONJ='}], 'text': 'поскольку'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'слабый', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'слабый'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'спутник', 'wt': 1, 'gr': 'S,муж=(им,ед,од|вин,ед,неод|им,ед,неод)'}], 'text': 'спутник'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'оставаться', 'wt': 1, 'gr': 'V,нп=прош,ед,изъяв,муж,несов'}], 'text': 'оставался'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'ненаблюдаемый', 'wt': 1, 'gr': 'A,полн=(дат,мн|твор,ед,муж|твор,ед,сред)'}], 'text': 'ненаблюдаемым'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'а', 'wt': 0.9822148501, 'gr': 'CONJ='}], 'text': 'а'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'его', 'wt': 3.284086391e-05, 'gr': 'APRO=(пр,мн|дат,мн|род,мн|твор,мн|им,мн|им,ед,жен|вин,ед,муж,од|род,ед,муж|род,ед,сред|вин,ед,сред|им,ед,сред|пр,ед,жен|дат,ед,жен|род,ед,жен|твор,ед,жен|пр,ед,муж|пр,ед,сред|дат,ед,муж|дат,ед,сред|вин,ед,жен|вин,мн,неод|вин,ед,муж,неод|им,ед,муж|твор,ед,муж|твор,ед,сред|вин,мн,од|пр,мн,сред|вин,мн,сред|дат,мн,сред|род,мн,сред|твор,мн,сред|им,мн,сред|пр,мн,муж|вин,мн,муж|вин,ед,муж|дат,мн,муж)'}], 'text': 'его'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'масса', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}], 'text': 'масса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'должный', 'wt': 1, 'gr': 'A=ед,кр,жен'}], 'text': 'должна'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'быть', 'wt': 1, 'gr': 'V,нп=прош,ед,изъяв,жен,несов'}], 'text': 'была'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'быть', 'wt': 1, 'gr': 'V,нп=инф,несов'}], 'text': 'быть'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'достаточно', 'wt': 0.591353536, 'gr': 'ADV='}], 'text': 'достаточно'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'большой', 'wt': 0.9952426116, 'gr': 'A=ед,кр,жен'}], 'text': 'велика'}\n",
      "{'text': ' — '}\n",
      "{'analysis': [{'lex': 'сравнимый', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'сравнимой'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'с', 'wt': 0.999977831, 'gr': 'PR='}], 'text': 'с'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'масса', 'wt': 1, 'gr': 'S,жен,неод=твор,ед'}], 'text': 'массой'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'процион', 'wt': 1, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}], 'text': 'Проциона'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'соответственно', 'wt': 0.759490663, 'gr': 'ADV='}], 'text': 'соответственно'}\n",
      "{'text': '.'}\n",
      "{'text': '\\n'}\n",
      "{'text': '\\n'}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'В'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'январь', 'wt': 0.9998020422, 'gr': 'S,муж,неод=пр,ед'}], 'text': 'январе'}\n",
      "{'text': ' '}\n",
      "{'text': '1862'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'год', 'wt': 1, 'gr': 'S,муж,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'года'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'элвин', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Элвин'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'грэхэм', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Грэхэм'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'кларк', 'wt': 0.6541957737, 'gr': 'S,фам,муж,од=им,ед'}], 'text': 'Кларк'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'юстировать', 'wt': 1, 'gr': 'V,пе=непрош,деепр,несов'}], 'text': 'юстируя'}\n",
      "{'text': ' '}\n",
      "{'text': '18'}\n",
      "{'text': '-'}\n",
      "{'analysis': [{'lex': 'дюймовый', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'дюймовый'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'рефрактор', 'wt': 1, 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'рефрактор'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'самый', 'wt': 1, 'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}], 'text': 'самый'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'большой', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж|пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'большой'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='}], 'text': 'на'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'то', 'wt': 0.4146576429, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}], 'text': 'то'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'время', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'время'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'телескоп', 'wt': 1, 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'телескоп'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'мир', 'wt': 0.9922263828, 'gr': 'S,муж,неод=пр,ед'}], 'text': 'мире'}\n",
      "{'text': ' ('}\n",
      "{'analysis': [], 'text': 'Dearborn'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'Telescope'}\n",
      "{'text': '), '}\n",
      "{'analysis': [{'lex': 'впоследствии', 'wt': 1, 'gr': 'ADV='}], 'text': 'впоследствии'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'поставлять', 'wt': 1, 'gr': 'V,пе=(прош,вин,ед,прич,полн,муж,сов,страд,неод|прош,им,ед,прич,полн,муж,сов,страд)'}], 'text': 'поставленный'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'семейный', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'семейной'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'фирма', 'wt': 1, 'gr': 'S,жен,неод=твор,ед'}], 'text': 'фирмой'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'кларк', 'wt': 0.6997748608, 'gr': 'S,муж,неод=род,мн'}], 'text': 'Кларков'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'обсерватория', 'wt': 1, 'gr': 'S,жен,неод=вин,ед'}], 'text': 'обсерваторию'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'чикагский', 'wt': 1, 'gr': 'A,гео=(вин,ед,полн,муж,од|род,ед,полн,муж|род,ед,полн,сред)'}], 'text': 'Чикагского'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'университет', 'wt': 1, 'gr': 'S,муж,неод=род,ед'}], 'text': 'университета'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'обнаруживать', 'wt': 1, 'gr': 'V,пе=прош,ед,изъяв,муж,сов'}], 'text': 'обнаружил'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'непосредственный', 'wt': 1, 'gr': 'A=(пр,ед,полн,жен|дат,ед,полн,жен|род,ед,полн,жен|твор,ед,полн,жен)'}], 'text': 'непосредственной'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'близость', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'близости'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'от', 'wt': 1, 'gr': 'PR='}], 'text': 'от'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'тусклый', 'wt': 1, 'gr': 'A=вин,ед,полн,жен'}], 'text': 'тусклую'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'звездочка', 'wt': 1, 'gr': 'S,жен,неод=вин,ед'}], 'text': 'звёздочку'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'это', 'wt': 0.7809833731, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}], 'text': 'Это'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'быть', 'wt': 1, 'gr': 'V,нп=прош,ед,изъяв,муж,несов'}], 'text': 'был'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'спутник', 'wt': 1, 'gr': 'S,муж=(им,ед,од|вин,ед,неод|им,ед,неод)'}], 'text': 'спутник'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}], 'text': 'Сириус'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'предсказывать', 'wt': 1, 'gr': 'V=(прош,вин,ед,прич,полн,муж,сов,страд,неод|прош,им,ед,прич,полн,муж,сов,страд)'}], 'text': 'предсказанный'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'бессель', 'wt': 1, 'gr': 'S,имя,муж,од=твор,ед'}], 'text': 'Бесселем'}\n",
      "{'text': '['}\n",
      "{'text': '6'}\n",
      "{'text': ']'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'а', 'wt': 0.9822148501, 'gr': 'CONJ='}], 'text': 'А'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'text': '1896'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'год', 'wt': 1, 'gr': 'S,муж,неод=(дат,ед|местн,ед)'}], 'text': 'году'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'американский', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'американский'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'астроном', 'wt': 1, 'gr': 'S,муж,од=им,ед'}], 'text': 'астроном'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'д', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'Д'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'м', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'М'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'шеберль', 'wt': 0.1322817834, 'qual': 'bastard', 'gr': 'S,муж,неод=пр,ед'}], 'text': 'Шеберле'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'открывать', 'wt': 1, 'gr': 'V=прош,ед,изъяв,муж,сов'}], 'text': 'открыл'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'процион', 'wt': 1, 'qual': 'bastard', 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'Процион'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'подтвердить', 'wt': 0.8641491534, 'gr': 'V,сов,нп=прош,деепр'}], 'text': 'подтвердив'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'то', 'wt': 0.6993998155, 'gr': 'SPRO,ед,сред,неод=твор'}], 'text': 'тем'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'самый', 'wt': 1, 'gr': 'APRO=(дат,мн|твор,ед,муж|твор,ед,сред)'}], 'text': 'самым'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'второй', 'wt': 0.9241041717, 'gr': 'ANUM=(вин,ед,сред|им,ед,сред)'}], 'text': 'второе'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'предсказание', 'wt': 1, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'предсказание'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'бессель', 'wt': 1, 'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}], 'text': 'Бесселя'}\n",
      "{'text': '.'}\n",
      "{'text': '\\n'}\n",
      "{'text': '\\n'}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'В'}\n",
      "{'text': ' '}\n",
      "{'text': '1915'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'год', 'wt': 1, 'gr': 'S,муж,неод=(дат,ед|местн,ед)'}], 'text': 'году'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'американский', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'американский'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'астроном', 'wt': 1, 'gr': 'S,муж,од=им,ед'}], 'text': 'астроном'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'уолтер', 'wt': 1, 'gr': 'S,имя,муж,од=им,ед'}], 'text': 'Уолтер'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сидней', 'wt': 0.8818068541, 'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}], 'text': 'Сидней'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'адамс', 'wt': 0.9243308352, 'gr': 'S,фам,муж,од=им,ед'}], 'text': 'Адамс'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'измерять', 'wt': 1, 'gr': 'V,пе=прош,ед,изъяв,муж,сов'}], 'text': 'измерил'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'спектр', 'wt': 0.9946207043, 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'спектр'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': '. '}\n",
      "{'analysis': [{'lex': 'из', 'wt': 0.9999999775, 'gr': 'PR='}], 'text': 'Из'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'измерение', 'wt': 1, 'gr': 'S,сред,неод=род,мн'}], 'text': 'измерений'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'следовать', 'wt': 0, 'gr': 'V,несов=прош,ед,изъяв,сред'}], 'text': 'следовало'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'что', 'wt': 0.688532576, 'gr': 'CONJ='}], 'text': 'что'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'его', 'wt': 3.284086391e-05, 'gr': 'APRO=(пр,мн|дат,мн|род,мн|твор,мн|им,мн|им,ед,жен|вин,ед,муж,од|род,ед,муж|род,ед,сред|вин,ед,сред|им,ед,сред|пр,ед,жен|дат,ед,жен|род,ед,жен|твор,ед,жен|пр,ед,муж|пр,ед,сред|дат,ед,муж|дат,ед,сред|вин,ед,жен|вин,мн,неод|вин,ед,муж,неод|им,ед,муж|твор,ед,муж|твор,ед,сред|вин,мн,од|пр,мн,сред|вин,мн,сред|дат,мн,сред|род,мн,сред|твор,мн,сред|им,мн,сред|пр,мн,муж|вин,мн,муж|вин,ед,муж|дат,мн,муж)'}], 'text': 'его'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'температура', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}], 'text': 'температура'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'низкий', 'wt': 0.3520033513, 'gr': 'A=срав'}], 'text': 'ниже'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'чем', 'wt': 0.8023791472, 'gr': 'CONJ='}], 'text': 'чем'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'у', 'wt': 0.9993940324, 'gr': 'PR='}], 'text': 'у'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'A'}\n",
      "{'text': ' ('}\n",
      "{'analysis': [{'lex': 'по', 'wt': 1, 'gr': 'PR='}], 'text': 'по'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'современный', 'wt': 1, 'gr': 'A=(дат,мн,полн|твор,ед,полн,муж|твор,ед,полн,сред)'}], 'text': 'современным'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'данные', 'wt': 0.9553083191, 'gr': 'S,мн,неод=дат'}], 'text': 'данным'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'температура', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}], 'text': 'температура'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'поверхность', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'поверхности'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'B'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'составлять', 'wt': 1, 'gr': 'V,пе=непрош,ед,изъяв,3-л,несов'}], 'text': 'составляет'}\n",
      "{'text': ' '}\n",
      "{'text': '25'}\n",
      "{'text': ' '}\n",
      "{'text': '000'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'K'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'а', 'wt': 0.9822148501, 'gr': 'CONJ='}], 'text': 'а'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'A'}\n",
      "{'text': ' — '}\n",
      "{'text': '10'}\n",
      "{'text': ' '}\n",
      "{'text': '000'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'к', 'wt': 4.48202392e-05, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'К'}\n",
      "{'text': '), '}\n",
      "{'analysis': [{'lex': 'что', 'wt': 0.2934446278, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}], 'text': 'что'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'с', 'wt': 0.999977831, 'gr': 'PR='}], 'text': 'с'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'учет', 'wt': 1, 'gr': 'S,муж,неод=твор,ед'}], 'text': 'учётом'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'он', 'wt': 0.9242062374, 'gr': 'SPRO,ед,3-л,муж=(вин|род)'}], 'text': 'его'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'в', 'wt': 0.9999917878, 'gr': 'PR='}], 'text': 'в'}\n",
      "{'text': ' '}\n",
      "{'text': '10'}\n",
      "{'text': ' '}\n",
      "{'text': '000'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'раз', 'wt': 0.9278416023, 'gr': 'S,муж,неод=(вин,ед|род,мн|им,ед)'}], 'text': 'раз'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'меньший', 'wt': 1, 'gr': 'A,полн=(пр,ед,жен|дат,ед,жен|род,ед,жен|твор,ед,жен)'}], 'text': 'меньшей'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'чем', 'wt': 0.8023791472, 'gr': 'CONJ='}], 'text': 'чем'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'у', 'wt': 0.9993940324, 'gr': 'PR='}], 'text': 'у'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' '}\n",
      "{'analysis': [], 'text': 'A'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'светимость', 'wt': 1, 'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}], 'text': 'светимости'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'указывать', 'wt': 1, 'gr': 'V=непрош,ед,изъяв,3-л,несов,пе'}], 'text': 'указывает'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'на', 'wt': 0.9989522965, 'gr': 'PR='}], 'text': 'на'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'очень', 'wt': 1, 'gr': 'ADV='}], 'text': 'очень'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'малый', 'wt': 0.7365821443, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'малый'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'радиус', 'wt': 1, 'gr': 'S,муж,неод=(вин,ед|им,ед)'}], 'text': 'радиус'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'соответственно', 'wt': 0.759490663, 'gr': 'ADV='}], 'text': 'соответственно'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'высокий', 'wt': 1, 'gr': 'A=вин,ед,полн,жен'}], 'text': 'высокую'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'плотность', 'wt': 1, 'gr': 'S,жен,неод=(вин,ед|им,ед)'}], 'text': 'плотность'}\n",
      "{'text': ' — '}\n",
      "{'text': '106'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'г', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'г'}\n",
      "{'text': '/'}\n",
      "{'text': 'см3'}\n",
      "{'text': ' ('}\n",
      "{'analysis': [{'lex': 'плотность', 'wt': 1, 'gr': 'S,жен,неод=(вин,ед|им,ед)'}], 'text': 'плотность'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'сириус', 'wt': 1, 'gr': 'S,гео,муж,неод=род,ед'}], 'text': 'Сириуса'}\n",
      "{'text': ' ~'}\n",
      "{'text': '0'}\n",
      "{'text': ','}\n",
      "{'text': '25'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'г', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'г'}\n",
      "{'text': '/'}\n",
      "{'text': 'см3'}\n",
      "{'text': ', '}\n",
      "{'analysis': [{'lex': 'плотность', 'wt': 1, 'gr': 'S,жен,неод=(вин,ед|им,ед)'}], 'text': 'плотность'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'солнце', 'wt': 1, 'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}], 'text': 'Солнца'}\n",
      "{'text': ' ~'}\n",
      "{'text': '1'}\n",
      "{'text': ','}\n",
      "{'text': '4'}\n",
      "{'text': ' '}\n",
      "{'analysis': [{'lex': 'г', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'г'}\n",
      "{'text': '/'}\n",
      "{'text': 'см3'}\n",
      "{'text': ')'}\n",
      "{'text': '.'}\n",
      "{'text': '\\n'}\n"
     ]
    }
   ],
   "source": [
    "import pymystem3\n",
    "\n",
    "mystem = pymystem3.Mystem(disambiguation=True)\n",
    "\n",
    "for sent in mystem.analyze(text):\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В целом обсуждение двух токенизаторов можно было бы закончить уже на том, что Mystem выдает совершенно не нужный в рамках настоящей задачи разбор с грамматическим тегами, леммами и пр. Однако ситауция обязывает поговорить про <s>плюсы и</s> минусы обоих.\n",
    "\n",
    "Оба токенизатора не справляются с тем, чтобы объединить в один токен числа вида `\"25 000\"` (с сепаратором-пробелом) \n",
    "\n",
    "- `razdel.tokenize`\n",
    "    1) разделяет единицы измерения:\n",
    "        - Substring(1564, 1565, 'г')\n",
    "        - Substring(1565, 1566, '/')\n",
    "        - Substring(1566, 1568, 'см')\n",
    "        - Substring(1568, 1569, '3')\n",
    "- `Mystem`\n",
    "    1) тоже разделяет единицы измерения, но иначе:\n",
    "        - {'analysis': [{'lex': 'г', 'wt': 1, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}], 'text': 'г'}\n",
    "        - {'text': '/'}\n",
    "        - {'text': 'см3'}\n",
    "    2) разделяет десятичные дроби:\n",
    "        - {'text': '0'}\n",
    "        - {'text': ','}\n",
    "        - {'text': '25'}\n",
    "    3) разделяет сложные слова с числом в первой части:\n",
    "        - {'text': '18'}\n",
    "        - {'text': '-'}\n",
    "        - {'analysis': [{'lex': 'дюймовый', 'wt': 1, 'gr': 'A=(вин,ед,полн,муж,неод|им,ед,полн,муж)'}], 'text': 'дюймовый'}\n",
    "\n",
    "Кажется, что `razdel.tokenize` лучше справляется с токенизацией на данном тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Лемматизация Mystem vs Pymorphy (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируйте текст с помощью mystem и pymorphy. Найдите различия в лемматизации. Что по вашему работает лучше на приведенном тексте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно: для пайморфи используйте токенизацию из mystem, чтобы исключить влияние токенизации на результат. Анализируйте только значимые различия, а не технические особенности (не сравнивайте скорость работы и удобность интерфейса).\n",
    "\n",
    "В майстеме убедитесь, что используется дизамбигуация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3 as pm\n",
    "\n",
    "morph = pm.MorphAnalyzer()\n",
    "pm_lemmatize_word = lambda word: morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_tokens = mystem.analyze(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\tmystem\tpm\n",
      "'стали'\t'становиться'\t'стать'\n",
      "'данные'\t'данные'\t'дать'\n",
      "'обнаружил'\t'обнаруживать'\t'обнаружить'\n",
      "'пришёл'\t'приходить'\t'прийти'\n",
      "'встречено'\t'встречать'\t'встретить'\n",
      "'его'\t'его'\t'он'\n",
      "'Грэхэм'\t'грэхэм'\t'грэхэма'\n",
      "'поставленный'\t'поставлять'\t'поставить'\n",
      "'обнаружил'\t'обнаруживать'\t'обнаружить'\n",
      "'предсказанный'\t'предсказывать'\t'предсказать'\n",
      "'Д'\t'д'\t'далее'\n",
      "'Шеберле'\t'шеберль'\t'шеберл'\n",
      "'открыл'\t'открывать'\t'открыть'\n",
      "'тем'\t'то'\t'тем'\n",
      "'второе'\t'второй'\t'второе'\n",
      "'измерил'\t'измерять'\t'измерить'\n",
      "'его'\t'его'\t'он'\n",
      "'ниже'\t'низкий'\t'ниже'\n",
      "'меньшей'\t'меньший'\t'малый'\n"
     ]
    }
   ],
   "source": [
    "print(\"word\", \"mystem\", \"pm\", sep=\"\\t\")\n",
    "for entry in mystem_tokens:\n",
    "\n",
    "    word = entry[\"text\"]\n",
    "\n",
    "    if \"analysis\" in entry and len(entry[\"analysis\"]) != 0:  ##  иначе попадают вот такие штуки: {'analysis': [], 'text': 'Dearborn'}\n",
    "        mystem_lemma = entry[\"analysis\"][0][\"lex\"]\n",
    "\n",
    "    else:  ##  В т.ч. посмотрим, как pm ведет себя с числами, пунктуацией и пр.\n",
    "        mystem_lemma = word\n",
    "\n",
    "    pm_lemma = pm_lemmatize_word(word)\n",
    "\n",
    "    ##  .lower() фильтрует вот такие штуки:\n",
    "    ##  mystem: 'Telescope', pm: 'telescope'\n",
    "    if pm_lemma.replace(\"ё\", \"е\").lower() != mystem_lemma.lower():   \n",
    "        print(repr(word), repr(mystem_lemma), repr(pm_lemma), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "В Mystem отсутствует поддержка буквы \"ё\", в pm она есть. В результатах выше этот момент отфильтрован, но вообще наличие буквы \"ё\" в анализе это всегда очень круто.\n",
    "\n",
    "Касательно глаголов, Mystem лемматизирует в несовершенный вид, а pm -- в совершенный. Разница не очень большая, но при построении NLP-конвейеров её нужно учитывать.\n",
    "\n",
    "По какой-то причине Mystem оставляет слово \"его\" без изменений.\n",
    "\n",
    "pm лемматизирует\"д\" как \"далее\", что местами, конечно, может быть полезно, но вообще нормализацию сокращений, тем более без контекста, никто не просил.\n",
    "\n",
    "Mystem лучше делает предсказания в случаях с **потенциально** неизвестными токенами:\n",
    "- 'Шеберле'\t'шеберль'\t'шеберл'\n",
    "- 'Грэхэм'\t'грэхэм'\t'грэхэма'\n",
    "\n",
    "По какой-то причине pm выдает первый парс для слова \"второе\" как имя существительное, что плохо.\n",
    "\n",
    "В целом в рамках настоящего текста оба анализатора показывают хорошие результаты по лемматизации, однако, учитывая встроенную в Mystem функциональность по снятию многозначности, а так же качественную работу с неизвестными токенами, кажется, что лучше отдать предпочтение ему овер Pymorphy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Лемматизация в SpaCy (2 балла)\n",
    "\n",
    "С помощью Spacy (модель для русского языка) лемматизируйте тот же текст. Проверьте есть ли различия с Mystem и Pymoprhy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_lemmas = []\n",
    "for sent in doc.sents: # достаем предложения\n",
    "    for token in sent: # достаем токены\n",
    "        if  token.pos_ != \"PUNCT\":\n",
    "            spacy_lemmas.append(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Анализ Pymorphy3 в итоге совсем немного хуже Mystem, эти можно пренебречь.\n",
    "## Сравним работу Spacy и Mystem:\n",
    "\n",
    "mystem_lemmas = [\n",
    "    entry[\"analysis\"][0][\"lex\"]\n",
    "    for entry\n",
    "    in mystem_tokens\n",
    "    if \"analysis\" in entry and len(entry[\"analysis\"]) != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 199)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенизация сильно повлияла:\n",
    "len(spacy_lemmas), len(mystem_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'встречать',\n",
       " 'д',\n",
       " 'дюймовый',\n",
       " 'звездочка',\n",
       " 'измерять',\n",
       " 'кенигсбергский',\n",
       " 'который',\n",
       " 'м',\n",
       " 'меньший',\n",
       " 'обнаруживать',\n",
       " 'они',\n",
       " 'открывать',\n",
       " 'поставлять',\n",
       " 'предсказывать',\n",
       " 'приходить',\n",
       " 'становиться',\n",
       " 'сфера',\n",
       " 'то',\n",
       " 'учет',\n",
       " 'чикагский',\n",
       " 'шеберль'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Это не оч правильно, но сравним разности множеств токенов:\n",
    "\n",
    "set(mystem_lemmas) - set(spacy_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " '\\n\\n',\n",
       " '000',\n",
       " '10',\n",
       " '106',\n",
       " '1755',\n",
       " '18-дюймовый',\n",
       " '1844',\n",
       " '1862',\n",
       " '1896',\n",
       " '1915',\n",
       " '25',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b.',\n",
       " 'dearborn',\n",
       " 'k',\n",
       " 'telescope',\n",
       " '~0,25',\n",
       " '~1,4',\n",
       " 'Из',\n",
       " 'бесселем[6',\n",
       " 'бесселя',\n",
       " 'было',\n",
       " 'встретить',\n",
       " 'д.',\n",
       " 'данным',\n",
       " 'звёздочка',\n",
       " 'измерить',\n",
       " 'кларков',\n",
       " 'которые',\n",
       " 'кёнигсбергский',\n",
       " 'м.',\n",
       " 'них',\n",
       " 'обнаружить',\n",
       " 'открыть',\n",
       " 'поставить',\n",
       " 'предсказанный',\n",
       " 'прийти',\n",
       " 'проциона',\n",
       " 'самым',\n",
       " 'см3',\n",
       " 'стать',\n",
       " 'сфере[5',\n",
       " 'тем',\n",
       " 'тот',\n",
       " 'учёт',\n",
       " 'чикагского',\n",
       " 'шеберле'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(spacy_lemmas) - set(mystem_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "Поверхностный анализ показывает, что Spacy работет хуже и лемматизирует не везде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5*. LSH (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*необязательное задание чтобы получить 10 баллов\n",
    "\n",
    "Попробуйте искать дубликаты в настоящих текстах. Например, можете взять https://github.com/mannefedov/compling_nlp_hse_course/blob/master/data/anna_karenina.txt или https://github.com/mannefedov/compling_nlp_hse_course/blob/master/data/besy_dostoevsky.txt (или любой другой корпус)\n",
    "\n",
    "Используйте код из семинара для нахождения кандидатов в дубликаты (шинглы -> минхэш - lsh) и рассчитайте реальную меру Жаккара между полученными кандидатами. Настройте параметры k, num_hash_functions, bands так чтобы результаты получались адекватные (мера Жаккара хотя бы больше нуля). \n",
    "\n",
    "(Можете взять 500-1000 текстов если весь корпус обрабатывается слишком долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/besy_dostoevsky.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shingles(text, k=5):\n",
    "    \"\"\"генерирует список шинглов из строки\"\"\"\n",
    "    shingles = set()\n",
    "    for i in range(len(text) - k + 1):\n",
    "        shingle = text[i:i + k]\n",
    "        shingles.add(shingle)\n",
    "    return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def hash_string(s):\n",
    "    \"\"\"хеширует строку и возвращает число\"\"\"\n",
    "    return int(hashlib.md5(s.encode('utf8')).hexdigest(), 16) \n",
    "\n",
    "def generate_hash_functions(k):\n",
    "    \"\"\"генерирует k хеш-функций добавляя индекс к строке\"\"\"\n",
    "\n",
    "    functions = []\n",
    "    for i in range(k):\n",
    "        functions.append(lambda x, i=i: hash_string(x + str(i)))\n",
    "    return functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minhash_signature(shingles, hash_funcs):\n",
    "    \"\"\"вычисляет minhash-сигнатуру для списка шинглов\"\"\"\n",
    "    signature = []\n",
    "    for hash_func in hash_funcs:\n",
    "        try:\n",
    "            min_hash = min(hash_func(shingle) for shingle in shingles)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        signature.append(min_hash)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def lsh(signatures, bands):\n",
    "    \"\"\"Разрезает сигнатуры на куски (bands), и группирует индексы сигнатур по совпадению кусков\"\"\"\n",
    "    buckets = defaultdict(list)\n",
    "    band_length = len(signatures[0]) // bands\n",
    "    \n",
    "    for idx, sig in tqdm(enumerate(signatures)):\n",
    "        for b in range(0, bands, band_length):\n",
    "            start = b\n",
    "            end = start + band_length\n",
    "            band = tuple(sig[start:end])\n",
    "            buckets[band].append(idx)\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_strings(strings_list, k=5, num_hashes=100, bands=20):\n",
    "    \"\"\"Finds similar strings using MinHash and LSH.\"\"\"\n",
    "    hash_funcs = generate_hash_functions(num_hashes)\n",
    "    signatures = []\n",
    "    shingles_list = []\n",
    "\n",
    "    # каждый текст обрабатывается отдельно\n",
    "    # находятся шинглы и рассчитываются сигнатуры \n",
    "    for string in tqdm(strings_list):\n",
    "        shingles = get_shingles(string, k)\n",
    "        shingles_list.append(shingles)\n",
    "        signature = compute_minhash_signature(shingles, hash_funcs)\n",
    "        signatures.append(signature)\n",
    "\n",
    "    # вычисляются кандидаты по кускам сигнатур\n",
    "    buckets = lsh(signatures, bands)\n",
    "    candidates = set()\n",
    "    for bucket in buckets.values():\n",
    "        if len(bucket) > 1:\n",
    "            for i in bucket:\n",
    "                for j in bucket:\n",
    "                    if i < j:\n",
    "                        candidates.add((i, j))\n",
    "\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'И вышли жители смотреть случившееся и, пришедши к Иисусу, нашли человека, из которого вышли бесы, сидящего у ног Иисусовых, одетого и в здравом уме, и ужаснулись.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = [sentence.text for sentence in sentenize(book) if sentence.text][:2000]\n",
    "strings[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:22<00:00, 24.20it/s]\n",
      "2000it [00:00, 60204.17it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates = find_similar_strings(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(26, 61),\n",
       " (304, 1021),\n",
       " (304, 1101),\n",
       " (304, 1144),\n",
       " (304, 1948),\n",
       " (304, 1990),\n",
       " (747, 863),\n",
       " (842, 1089),\n",
       " (907, 1730),\n",
       " (922, 958),\n",
       " (1021, 1101),\n",
       " (1021, 1144),\n",
       " (1021, 1948),\n",
       " (1021, 1990),\n",
       " (1101, 1144),\n",
       " (1101, 1948),\n",
       " (1101, 1990),\n",
       " (1144, 1948),\n",
       " (1144, 1990),\n",
       " (1229, 1311),\n",
       " (1241, 1249),\n",
       " (1242, 1243),\n",
       " (1242, 1244),\n",
       " (1243, 1244),\n",
       " (1560, 1563),\n",
       " (1744, 1750),\n",
       " (1948, 1990)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## без такой доработки get_jaccard падает с делением на 0\n",
    "\n",
    "class JaccardException(Exception):\n",
    "    def __init__(self):            \n",
    "        super().__init__(\"Деление на 0: сделайте k меньше.\")\n",
    "\n",
    "\n",
    "def get_jaccard(x, y, k):\n",
    "    x_sh = get_shingles(x, k)\n",
    "    y_sh = get_shingles(y, k)\n",
    "\n",
    "    if not (x_sh or y_sh):\n",
    "        raise JaccardException\n",
    "\n",
    "    return len(x_sh & y_sh) / len(x_sh | y_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_shingle_size = 10  \n",
    "min_shingle_size = 5\n",
    "\n",
    "jac_OK = []\n",
    "jac_FAIL = []\n",
    "\n",
    "for c1, c2 in candidates:\n",
    "\n",
    "    sh1 = strings[c1]\n",
    "    sh2 = strings[c2]\n",
    "\n",
    "    for i in range(max_shingle_size, min_shingle_size, -1):\n",
    "        try:\n",
    "            jac = get_jaccard(sh1, sh2, i)\n",
    "        except JaccardException:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        jac_FAIL.append(f\"Не вышло посчитать jaccard для {repr(sh1)} и {repr(sh2)}.\")\n",
    "\n",
    "    jac_OK.append(f\"{repr(sh1)}\\t{repr(sh1)}\\t{jac}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ну?'\t'Ну?'\t1.0\n",
      "'Нет!'\t'Нет!'\t1.0\n",
      "'—\\xa0Так я и знала!'\t'—\\xa0Так я и знала!'\t1.0\n",
      "'Ну?'\t'Ну?'\t1.0\n",
      "'Куда же вы?'\t'Куда же вы?'\t0.3333333333333333\n",
      "'—\\xa0О!'\t'—\\xa0О!'\t0.3333333333333333\n",
      "'(NB.'\t'(NB.'\t0.3333333333333333\n",
      "'Нет!'\t'Нет!'\t0.3333333333333333\n",
      "'Садитесь же, наконец, прошу вас.'\t'Садитесь же, наконец, прошу вас.'\t1.0\n",
      "'—\\xa0Все-таки замечательное совпадение.'\t'—\\xa0Все-таки замечательное совпадение.'\t0.48484848484848486\n",
      "'—\\xa0Как?'\t'—\\xa0Как?'\t1.0\n",
      "'Ну?'\t'Ну?'\t1.0\n",
      "'(NB.'\t'(NB.'\t1.0\n",
      "'Ну?'\t'Ну?'\t1.0\n",
      "'Куда же вы?'\t'Куда же вы?'\t0.3333333333333333\n",
      "'Настасья, Настасья!'\t'Настасья, Настасья!'\t1.0\n",
      "'Нет!'\t'Нет!'\t1.0\n",
      "'В. С.»'\t'В. С.»'\t1.0\n",
      "'— Какую сестру?'\t'— Какую сестру?'\t0.6666666666666666\n",
      "'Нет!'\t'Нет!'\t0.6666666666666666\n",
      "'Ну?'\t'Ну?'\t0.6666666666666666\n",
      "'О, как вы меня мучаете!'\t'О, как вы меня мучаете!'\t0.875\n",
      "'(NB.'\t'(NB.'\t0.875\n",
      "'И что же?'\t'И что же?'\t1.0\n",
      "'Куда же вы?'\t'Куда же вы?'\t1.0\n",
      "'Нет!'\t'Нет!'\t1.0\n",
      "'(NB.'\t'(NB.'\t1.0\n"
     ]
    }
   ],
   "source": [
    "for entry in jac_OK:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не вышло посчитать jaccard для 'Ну?' и '—\\xa0О!'.\n",
      "Не вышло посчитать jaccard для 'Нет!' и '—\\xa0О!'.\n",
      "Не вышло посчитать jaccard для 'Ну?' и 'Так?'.\n",
      "Не вышло посчитать jaccard для '—\\xa0О!' и 'Так?'.\n",
      "Не вышло посчитать jaccard для '(NB.' и '—\\xa0О!'.\n",
      "Не вышло посчитать jaccard для 'Нет!' и 'Так?'.\n",
      "Не вышло посчитать jaccard для 'Ну?' и '—\\xa0О!'.\n",
      "Не вышло посчитать jaccard для '(NB.' и 'Так?'.\n",
      "Не вышло посчитать jaccard для 'Ну?' и 'Ну?'.\n",
      "Не вышло посчитать jaccard для 'Нет!' и 'Ну?'.\n",
      "Не вышло посчитать jaccard для 'Нет!' и 'Ну?'.\n",
      "Не вышло посчитать jaccard для 'Ну?' и 'Так?'.\n",
      "Не вышло посчитать jaccard для '(NB.' и 'Ну?'.\n",
      "Не вышло посчитать jaccard для 'Нет!' и '(NB.'.\n",
      "Не вышло посчитать jaccard для '(NB.' и 'Ну?'.\n"
     ]
    }
   ],
   "source": [
    "for entry in jac_FAIL:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комментарий\n",
    "\n",
    "Пришлось обернуть `min_hash = min(hash_func(shingle) for shingle in shingles)` в `try... except...` потому валилось с ValueError.\n",
    "\n",
    "Пришлось доработать `get_jaccard` чтобы не валиться с `ZeroDivisionError`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
